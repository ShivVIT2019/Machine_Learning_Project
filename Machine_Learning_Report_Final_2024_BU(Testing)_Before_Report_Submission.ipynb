{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Packages"
      ],
      "metadata": {
        "id": "Dec0KbRXOTw-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adnlO6gYKbWe",
        "outputId": "17c21014-dbf8-4756-dfa2-ddd7ef516877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Cloning into 'moco'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (124/124), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 124 (delta 58), reused 101 (delta 49), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (124/124), 64.75 KiB | 2.40 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "/content/moco\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install PyTorch with GPU support\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Clone the MoCo repository\n",
        "!git clone https://github.com/facebookresearch/moco.git\n",
        "%cd moco\n",
        "\n",
        "# Install other dependencies (if needed)\n",
        "!pip install numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Packages\n",
        "# We are Taking cifar 10 dataset instead of Image Net as prescribed in the paper"
      ],
      "metadata": {
        "id": "D4-4LLLvOXpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define CIFAR-10 dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),  # Resize to 224x224 (like ImageNet)\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-snErn7Km7L",
        "outputId": "56d21b90-a0e8-4cfa-ad36-07506de7e299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 74.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting the path"
      ],
      "metadata": {
        "id": "qfVP4HQPOjsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split\n",
        "from shutil import rmtree\n",
        "from PIL import Image\n",
        "\n",
        "# Paths for the dataset\n",
        "data_root = './data'\n",
        "train_dir = os.path.join(data_root, 'train')\n",
        "val_dir = os.path.join(data_root, 'val')\n",
        "\n",
        "# Transformation for CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Download the CIFAR-10 dataset\n",
        "cifar10_full = datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform)\n",
        "cifar10_test = datasets.CIFAR10(root=data_root, train=False, download=True, transform=transform)\n",
        "\n",
        "# Split CIFAR-10 into train and validation (50,000 train, 10,000 val)\n",
        "train_size = int(0.8 * len(cifar10_full))\n",
        "val_size = len(cifar10_full) - train_size\n",
        "train_dataset, val_dataset = random_split(cifar10_full, [train_size, val_size])\n",
        "\n",
        "# Helper function to save images into class-based directories\n",
        "def save_dataset(dataset, target_dir):\n",
        "    if os.path.exists(target_dir):\n",
        "        rmtree(target_dir)\n",
        "    os.makedirs(target_dir)\n",
        "    for idx, (image, label) in enumerate(dataset):\n",
        "        class_dir = os.path.join(target_dir, str(label))\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        # Convert tensor to PIL image\n",
        "        pil_image = transforms.ToPILImage()(image)\n",
        "        pil_image.save(os.path.join(class_dir, f\"{idx}.png\"))\n",
        "\n",
        "# Save the datasets\n",
        "save_dataset(train_dataset, train_dir)\n",
        "save_dataset(val_dataset, val_dir)\n",
        "\n",
        "print(\"Datasets saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCQ0oKxh-zW3",
        "outputId": "b635f2e7-b361-46b0-8000-1a108428a2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Datasets saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./data/train/\n",
        "!ls ./data/val/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE1CSk86_K0v",
        "outputId": "8d8bf608-484a-4f1d-fac0-02c9c8005009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  1  2  3  4  5  6  7\t8  9\n",
            "0  1  2  3  4  5  6  7\t8  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nmpiuwD_eRB",
        "outputId": "a54926a5-9c0b-44aa-8e5f-be9ff9da7ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb1qSV1sZQF2",
        "outputId": "aa705e54-a81b-41aa-f66d-2920e99db0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GGgkmBPJaR15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_moco.py ./data --gpu 0 --batch-size 128 --epochs 200"
      ],
      "metadata": {
        "id": "_X9orXtO8op9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d6a557-e559-43fe-8164-f57418286c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/moco/main_moco.py:196: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "  warnings.warn(\n",
            "Use GPU: 0 for training\n",
            "=> creating model 'resnet50'\n",
            "MoCo(\n",
            "  (encoder_q): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=2048, out_features=128, bias=True)\n",
            "  )\n",
            "  (encoder_k): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=2048, out_features=128, bias=True)\n",
            "  )\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/moco/main_moco.py\", line 519, in <module>\n",
            "    main()\n",
            "  File \"/content/moco/main_moco.py\", line 216, in main\n",
            "    main_worker(args.gpu, ngpus_per_node, args)\n",
            "  File \"/content/moco/main_moco.py\", line 279, in main_worker\n",
            "    torch.cuda.set_device(args.gpu)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 478, in set_device\n",
            "    torch._C._cuda_setDevice(device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 319, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCMwOASSWBgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Current Directory:\", os.getcwd())\n",
        "print(\"File Exists:\", os.path.exists('checkpoint.pth.tar'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWseYhZYm3SR",
        "outputId": "ae90b8a8-ae3a-4239-e58f-d86b9858e48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory: /content/moco\n",
            "File Exists: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_200ep/.pth.tar -O moco_v2_checkpoint_200.pth.tar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCU8lAW8qK2y",
        "outputId": "b7ab52b6-a3e8-4a53-89b1-12e6e90b0a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-19 18:09:13--  https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_200ep/.pth.tar\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.102, 108.157.254.121, 108.157.254.15, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 403 Forbidden\n",
            "2024-11-19 18:09:14 ERROR 403: Forbidden.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"File Exists:\", os.path.exists('moco_v2_checkpoint_200.pth.tar'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SKQFSqcrcrL",
        "outputId": "05645d3b-e490-4f71-c344-c878f5c1b0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Define a ResNet-50 model\n",
        "model = models.resnet50()\n"
      ],
      "metadata": {
        "id": "r9R9azRFrt0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint = torch.load('moco_v2_checkpoint_200.pth.tar', map_location='cuda:0')\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(checkpoint['state_dict'], strict=False)  # Use strict=False if not all keys match\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "dQJG9N9drgHq",
        "outputId": "3680c56b-a5d8-4e3f-a0b9-d2a9b36e60b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-ec30e35f0d53>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('moco_v2_checkpoint_200.pth.tar', map_location='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "Ran out of input",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ec30e35f0d53>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'moco_v2_checkpoint_200.pth.tar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the state dictionary into the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m         return _legacy_load(\n\u001b[0m\u001b[1;32m   1385\u001b[0m             \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1626\u001b[0m         )\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cuda()\n",
        "model.eval()  # Set model to evaluation mode if testing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1tcVBlPrz_B",
        "outputId": "2bf12c6f-3f91-4a09-aefc-536b3b656ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transformations for the test dataset\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261]),\n",
        "])\n",
        "\n",
        "# Specify the dataset path\n",
        "test_dataset_path = '/content/moco/data/val'\n",
        "\n",
        "# Load the test dataset using ImageFolder\n",
        "test_dataset = ImageFolder(root=test_dataset_path, transform=test_transforms)\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Test dataset loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbHYAq3SsnDt",
        "outputId": "1bad0f52-8d26-4dcb-8bac-23b7f753e199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# Load the pre-trained MoCo weights\n",
        "checkpoint = torch.load('moco_v2_checkpoint_200.pth.tar', map_location='cuda:0')\n",
        "\n",
        "# Extract the weights for encoder_q\n",
        "state_dict = checkpoint['state_dict']\n",
        "\n",
        "# Remove \"module.encoder_q.\" prefix from the keys in the state_dict\n",
        "new_state_dict = {k.replace(\"module.encoder_q.\", \"\"): v for k, v in state_dict.items() if \"encoder_q\" in k}\n",
        "\n",
        "# Initialize the standard ResNet-50 architecture\n",
        "model = resnet50(num_classes=128)  # MoCo's output feature dimension is 128\n",
        "model.load_state_dict(new_state_dict, strict=False)\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "\n",
        "# Test the model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6v2lAlRsro_",
        "outputId": "195d42ff-7edc-4edc-99e6-be7e8ac790ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-b398035c3377>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('moco_v2_checkpoint_200.pth.tar', map_location='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 1.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true = []  # Ground truth labels\n",
        "y_pred = []  # Model predictions\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.cuda()\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "ndp7vqZjtYZ_",
        "outputId": "f363872f-f30b-46ea-f66a-ac2fdf84a8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the final classification layer to extract features\n",
        "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "feature_extractor.eval()\n",
        "\n",
        "features = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in test_loader:\n",
        "        inputs = inputs.cuda()\n",
        "        outputs = feature_extractor(inputs)\n",
        "        features.append(outputs.cpu().numpy())\n",
        "\n",
        "print(\"Features extracted for downstream tasks.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THzTuvM2tnKM",
        "outputId": "f253ff1c-a3d5-4650-f7a8-4ad2a7a8f2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features extracted for downstream tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# Load the pre-trained MoCo model\n",
        "checkpoint = torch.load('moco_v2_checkpoint_200.pth.tar', map_location='cuda:0')\n",
        "\n",
        "# Initialize the ResNet-50 backbone\n",
        "model = resnet50(num_classes=128)  # MoCo uses 128-dimensional embeddings\n",
        "model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
        "\n",
        "# Modify the fully connected layer for CIFAR-10\n",
        "num_classes = 10  # Replace with the number of classes in your dataset\n",
        "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
        "\n",
        "model = model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cXhRrRjt7p4",
        "outputId": "7270d562-9db6-4624-a0e5-92e8e6172354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-e72f13ff7b11>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('moco_v2_checkpoint_200.pth.tar', map_location='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "3XKJaVrXt-Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "MuWP3bFOuHlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grcH809TuKAZ",
        "outputId": "cd170f72-6b01-4e9a-ed76-061a2f7372a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "KUaEIqObuMDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define data transformations for the training dataset\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 training dataset\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "# Unfreeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Define optimizer and loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Fine-tune the model on your training dataset\n",
        "for epoch in range(250):  # Choose the number of epochs\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 100 == 0:  # Print loss every 100 batches\n",
        "            print(f\"Epoch [{epoch+1}/250], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Fine-tuning completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O82Zt7tuVnK",
        "outputId": "fa99c538-dcf3-4e5c-dba0-b21aa75e8308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Epoch [1/250], Step [0/782], Loss: 1.9515\n",
            "Epoch [1/250], Step [100/782], Loss: 1.6781\n",
            "Epoch [1/250], Step [200/782], Loss: 1.7327\n",
            "Epoch [1/250], Step [300/782], Loss: 1.7393\n",
            "Epoch [1/250], Step [400/782], Loss: 2.1190\n",
            "Epoch [1/250], Step [500/782], Loss: 1.6230\n",
            "Epoch [1/250], Step [600/782], Loss: 1.9977\n",
            "Epoch [1/250], Step [700/782], Loss: 1.8725\n",
            "Epoch [2/250], Step [0/782], Loss: 1.9181\n",
            "Epoch [2/250], Step [100/782], Loss: 1.5802\n",
            "Epoch [2/250], Step [200/782], Loss: 1.7969\n",
            "Epoch [2/250], Step [300/782], Loss: 1.8759\n",
            "Epoch [2/250], Step [400/782], Loss: 1.6669\n",
            "Epoch [2/250], Step [500/782], Loss: 1.7099\n",
            "Epoch [2/250], Step [600/782], Loss: 1.6432\n",
            "Epoch [2/250], Step [700/782], Loss: 1.5814\n",
            "Epoch [3/250], Step [0/782], Loss: 1.5614\n",
            "Epoch [3/250], Step [100/782], Loss: 1.4069\n",
            "Epoch [3/250], Step [200/782], Loss: 1.4759\n",
            "Epoch [3/250], Step [300/782], Loss: 1.5059\n",
            "Epoch [3/250], Step [400/782], Loss: 1.3580\n",
            "Epoch [3/250], Step [500/782], Loss: 1.8125\n",
            "Epoch [3/250], Step [600/782], Loss: 1.4931\n",
            "Epoch [3/250], Step [700/782], Loss: 1.2934\n",
            "Epoch [4/250], Step [0/782], Loss: 1.4784\n",
            "Epoch [4/250], Step [100/782], Loss: 1.6734\n",
            "Epoch [4/250], Step [200/782], Loss: 1.6908\n",
            "Epoch [4/250], Step [300/782], Loss: 1.9387\n",
            "Epoch [4/250], Step [400/782], Loss: 1.0288\n",
            "Epoch [4/250], Step [500/782], Loss: 1.4889\n",
            "Epoch [4/250], Step [600/782], Loss: 1.6246\n",
            "Epoch [4/250], Step [700/782], Loss: 1.4922\n",
            "Epoch [5/250], Step [0/782], Loss: 1.4837\n",
            "Epoch [5/250], Step [100/782], Loss: 1.4902\n",
            "Epoch [5/250], Step [200/782], Loss: 1.5183\n",
            "Epoch [5/250], Step [300/782], Loss: 1.3555\n",
            "Epoch [5/250], Step [400/782], Loss: 1.6006\n",
            "Epoch [5/250], Step [500/782], Loss: 1.6405\n",
            "Epoch [5/250], Step [600/782], Loss: 1.3587\n",
            "Epoch [5/250], Step [700/782], Loss: 1.4578\n",
            "Epoch [6/250], Step [0/782], Loss: 1.4403\n",
            "Epoch [6/250], Step [100/782], Loss: 1.3088\n",
            "Epoch [6/250], Step [200/782], Loss: 1.4720\n",
            "Epoch [6/250], Step [300/782], Loss: 1.3256\n",
            "Epoch [6/250], Step [400/782], Loss: 1.5891\n",
            "Epoch [6/250], Step [500/782], Loss: 1.3263\n",
            "Epoch [6/250], Step [600/782], Loss: 1.6833\n",
            "Epoch [6/250], Step [700/782], Loss: 1.3976\n",
            "Epoch [7/250], Step [0/782], Loss: 1.3709\n",
            "Epoch [7/250], Step [100/782], Loss: 1.0999\n",
            "Epoch [7/250], Step [200/782], Loss: 1.2308\n",
            "Epoch [7/250], Step [300/782], Loss: 1.3644\n",
            "Epoch [7/250], Step [400/782], Loss: 1.3925\n",
            "Epoch [7/250], Step [500/782], Loss: 1.2842\n",
            "Epoch [7/250], Step [600/782], Loss: 1.2516\n",
            "Epoch [7/250], Step [700/782], Loss: 1.2615\n",
            "Epoch [8/250], Step [0/782], Loss: 1.5554\n",
            "Epoch [8/250], Step [100/782], Loss: 1.4281\n",
            "Epoch [8/250], Step [200/782], Loss: 1.3105\n",
            "Epoch [8/250], Step [300/782], Loss: 1.2694\n",
            "Epoch [8/250], Step [400/782], Loss: 1.2376\n",
            "Epoch [8/250], Step [500/782], Loss: 1.6826\n",
            "Epoch [8/250], Step [600/782], Loss: 1.5318\n",
            "Epoch [8/250], Step [700/782], Loss: 1.2553\n",
            "Epoch [9/250], Step [0/782], Loss: 1.2256\n",
            "Epoch [9/250], Step [100/782], Loss: 1.2250\n",
            "Epoch [9/250], Step [200/782], Loss: 1.4288\n",
            "Epoch [9/250], Step [300/782], Loss: 1.1281\n",
            "Epoch [9/250], Step [400/782], Loss: 1.3135\n",
            "Epoch [9/250], Step [500/782], Loss: 1.4694\n",
            "Epoch [9/250], Step [600/782], Loss: 1.4525\n",
            "Epoch [9/250], Step [700/782], Loss: 1.2270\n",
            "Epoch [10/250], Step [0/782], Loss: 1.2871\n",
            "Epoch [10/250], Step [100/782], Loss: 1.4202\n",
            "Epoch [10/250], Step [200/782], Loss: 1.1751\n",
            "Epoch [10/250], Step [300/782], Loss: 1.1971\n",
            "Epoch [10/250], Step [400/782], Loss: 1.3121\n",
            "Epoch [10/250], Step [500/782], Loss: 1.5703\n",
            "Epoch [10/250], Step [600/782], Loss: 1.2433\n",
            "Epoch [10/250], Step [700/782], Loss: 1.2950\n",
            "Epoch [11/250], Step [0/782], Loss: 1.0610\n",
            "Epoch [11/250], Step [100/782], Loss: 1.4547\n",
            "Epoch [11/250], Step [200/782], Loss: 1.0929\n",
            "Epoch [11/250], Step [300/782], Loss: 1.1913\n",
            "Epoch [11/250], Step [400/782], Loss: 1.0216\n",
            "Epoch [11/250], Step [500/782], Loss: 1.0505\n",
            "Epoch [11/250], Step [600/782], Loss: 1.3219\n",
            "Epoch [11/250], Step [700/782], Loss: 1.4150\n",
            "Epoch [12/250], Step [0/782], Loss: 1.1676\n",
            "Epoch [12/250], Step [100/782], Loss: 1.3437\n",
            "Epoch [12/250], Step [200/782], Loss: 1.1856\n",
            "Epoch [12/250], Step [300/782], Loss: 1.3399\n",
            "Epoch [12/250], Step [400/782], Loss: 1.2144\n",
            "Epoch [12/250], Step [500/782], Loss: 1.0825\n",
            "Epoch [12/250], Step [600/782], Loss: 1.3514\n",
            "Epoch [12/250], Step [700/782], Loss: 1.0960\n",
            "Epoch [13/250], Step [0/782], Loss: 1.1673\n",
            "Epoch [13/250], Step [100/782], Loss: 1.0556\n",
            "Epoch [13/250], Step [200/782], Loss: 1.1974\n",
            "Epoch [13/250], Step [300/782], Loss: 1.0684\n",
            "Epoch [13/250], Step [400/782], Loss: 1.2523\n",
            "Epoch [13/250], Step [500/782], Loss: 1.0935\n",
            "Epoch [13/250], Step [600/782], Loss: 1.0284\n",
            "Epoch [13/250], Step [700/782], Loss: 1.1272\n",
            "Epoch [14/250], Step [0/782], Loss: 1.3293\n",
            "Epoch [14/250], Step [100/782], Loss: 1.1850\n",
            "Epoch [14/250], Step [200/782], Loss: 1.0408\n",
            "Epoch [14/250], Step [300/782], Loss: 1.0477\n",
            "Epoch [14/250], Step [400/782], Loss: 1.4555\n",
            "Epoch [14/250], Step [500/782], Loss: 0.8646\n",
            "Epoch [14/250], Step [600/782], Loss: 1.1914\n",
            "Epoch [14/250], Step [700/782], Loss: 1.0673\n",
            "Epoch [15/250], Step [0/782], Loss: 0.9375\n",
            "Epoch [15/250], Step [100/782], Loss: 1.1425\n",
            "Epoch [15/250], Step [200/782], Loss: 1.3010\n",
            "Epoch [15/250], Step [300/782], Loss: 1.0829\n",
            "Epoch [15/250], Step [400/782], Loss: 1.3637\n",
            "Epoch [15/250], Step [500/782], Loss: 1.1694\n",
            "Epoch [15/250], Step [600/782], Loss: 0.9685\n",
            "Epoch [15/250], Step [700/782], Loss: 1.0681\n",
            "Epoch [16/250], Step [0/782], Loss: 0.7538\n",
            "Epoch [16/250], Step [100/782], Loss: 1.0741\n",
            "Epoch [16/250], Step [200/782], Loss: 0.8430\n",
            "Epoch [16/250], Step [300/782], Loss: 1.1179\n",
            "Epoch [16/250], Step [400/782], Loss: 1.1492\n",
            "Epoch [16/250], Step [500/782], Loss: 1.0233\n",
            "Epoch [16/250], Step [600/782], Loss: 0.8083\n",
            "Epoch [16/250], Step [700/782], Loss: 0.9660\n",
            "Epoch [17/250], Step [0/782], Loss: 1.0427\n",
            "Epoch [17/250], Step [100/782], Loss: 1.0224\n",
            "Epoch [17/250], Step [200/782], Loss: 1.0041\n",
            "Epoch [17/250], Step [300/782], Loss: 1.0566\n",
            "Epoch [17/250], Step [400/782], Loss: 1.3244\n",
            "Epoch [17/250], Step [500/782], Loss: 1.1216\n",
            "Epoch [17/250], Step [600/782], Loss: 1.2007\n",
            "Epoch [17/250], Step [700/782], Loss: 1.1689\n",
            "Epoch [18/250], Step [0/782], Loss: 1.0351\n",
            "Epoch [18/250], Step [100/782], Loss: 0.8402\n",
            "Epoch [18/250], Step [200/782], Loss: 1.2585\n",
            "Epoch [18/250], Step [300/782], Loss: 1.0331\n",
            "Epoch [18/250], Step [400/782], Loss: 1.0439\n",
            "Epoch [18/250], Step [500/782], Loss: 1.1845\n",
            "Epoch [18/250], Step [600/782], Loss: 0.9704\n",
            "Epoch [18/250], Step [700/782], Loss: 1.0379\n",
            "Epoch [19/250], Step [0/782], Loss: 0.9869\n",
            "Epoch [19/250], Step [100/782], Loss: 1.0507\n",
            "Epoch [19/250], Step [200/782], Loss: 1.0847\n",
            "Epoch [19/250], Step [300/782], Loss: 0.7401\n",
            "Epoch [19/250], Step [400/782], Loss: 0.7089\n",
            "Epoch [19/250], Step [500/782], Loss: 0.9980\n",
            "Epoch [19/250], Step [600/782], Loss: 1.1907\n",
            "Epoch [19/250], Step [700/782], Loss: 1.0149\n",
            "Epoch [20/250], Step [0/782], Loss: 0.9095\n",
            "Epoch [20/250], Step [100/782], Loss: 0.8541\n",
            "Epoch [20/250], Step [200/782], Loss: 0.8931\n",
            "Epoch [20/250], Step [300/782], Loss: 0.9385\n",
            "Epoch [20/250], Step [400/782], Loss: 0.7911\n",
            "Epoch [20/250], Step [500/782], Loss: 1.0224\n",
            "Epoch [20/250], Step [600/782], Loss: 0.8601\n",
            "Epoch [20/250], Step [700/782], Loss: 0.7578\n",
            "Epoch [21/250], Step [0/782], Loss: 0.7902\n",
            "Epoch [21/250], Step [100/782], Loss: 0.8757\n",
            "Epoch [21/250], Step [200/782], Loss: 0.7984\n",
            "Epoch [21/250], Step [300/782], Loss: 1.0776\n",
            "Epoch [21/250], Step [400/782], Loss: 0.8573\n",
            "Epoch [21/250], Step [500/782], Loss: 0.8063\n",
            "Epoch [21/250], Step [600/782], Loss: 1.0115\n",
            "Epoch [21/250], Step [700/782], Loss: 0.8213\n",
            "Epoch [22/250], Step [0/782], Loss: 0.9862\n",
            "Epoch [22/250], Step [100/782], Loss: 1.0880\n",
            "Epoch [22/250], Step [200/782], Loss: 1.1549\n",
            "Epoch [22/250], Step [300/782], Loss: 0.8209\n",
            "Epoch [22/250], Step [400/782], Loss: 0.8486\n",
            "Epoch [22/250], Step [500/782], Loss: 0.8831\n",
            "Epoch [22/250], Step [600/782], Loss: 0.6941\n",
            "Epoch [22/250], Step [700/782], Loss: 0.9631\n",
            "Epoch [23/250], Step [0/782], Loss: 0.8526\n",
            "Epoch [23/250], Step [100/782], Loss: 0.9825\n",
            "Epoch [23/250], Step [200/782], Loss: 0.8822\n",
            "Epoch [23/250], Step [300/782], Loss: 0.9251\n",
            "Epoch [23/250], Step [400/782], Loss: 0.9982\n",
            "Epoch [23/250], Step [500/782], Loss: 0.6332\n",
            "Epoch [23/250], Step [600/782], Loss: 0.9183\n",
            "Epoch [23/250], Step [700/782], Loss: 0.9909\n",
            "Epoch [24/250], Step [0/782], Loss: 0.9261\n",
            "Epoch [24/250], Step [100/782], Loss: 1.1959\n",
            "Epoch [24/250], Step [200/782], Loss: 0.8984\n",
            "Epoch [24/250], Step [300/782], Loss: 0.8251\n",
            "Epoch [24/250], Step [400/782], Loss: 0.8655\n",
            "Epoch [24/250], Step [500/782], Loss: 0.6269\n",
            "Epoch [24/250], Step [600/782], Loss: 1.1356\n",
            "Epoch [24/250], Step [700/782], Loss: 0.9641\n",
            "Epoch [25/250], Step [0/782], Loss: 0.7097\n",
            "Epoch [25/250], Step [100/782], Loss: 1.0585\n",
            "Epoch [25/250], Step [200/782], Loss: 0.8153\n",
            "Epoch [25/250], Step [300/782], Loss: 0.7859\n",
            "Epoch [25/250], Step [400/782], Loss: 0.7039\n",
            "Epoch [25/250], Step [500/782], Loss: 1.1286\n",
            "Epoch [25/250], Step [600/782], Loss: 0.9330\n",
            "Epoch [25/250], Step [700/782], Loss: 1.0180\n",
            "Epoch [26/250], Step [0/782], Loss: 0.9860\n",
            "Epoch [26/250], Step [100/782], Loss: 0.7758\n",
            "Epoch [26/250], Step [200/782], Loss: 0.8000\n",
            "Epoch [26/250], Step [300/782], Loss: 0.8988\n",
            "Epoch [26/250], Step [400/782], Loss: 0.6632\n",
            "Epoch [26/250], Step [500/782], Loss: 0.9308\n",
            "Epoch [26/250], Step [600/782], Loss: 0.9115\n",
            "Epoch [26/250], Step [700/782], Loss: 0.9122\n",
            "Epoch [27/250], Step [0/782], Loss: 0.6252\n",
            "Epoch [27/250], Step [100/782], Loss: 0.8023\n",
            "Epoch [27/250], Step [200/782], Loss: 0.8338\n",
            "Epoch [27/250], Step [300/782], Loss: 0.8105\n",
            "Epoch [27/250], Step [400/782], Loss: 0.8428\n",
            "Epoch [27/250], Step [500/782], Loss: 0.8811\n",
            "Epoch [27/250], Step [600/782], Loss: 1.2337\n",
            "Epoch [27/250], Step [700/782], Loss: 0.7253\n",
            "Epoch [28/250], Step [0/782], Loss: 0.8745\n",
            "Epoch [28/250], Step [100/782], Loss: 0.7386\n",
            "Epoch [28/250], Step [200/782], Loss: 0.8641\n",
            "Epoch [28/250], Step [300/782], Loss: 0.8929\n",
            "Epoch [28/250], Step [400/782], Loss: 0.7577\n",
            "Epoch [28/250], Step [500/782], Loss: 0.7292\n",
            "Epoch [28/250], Step [600/782], Loss: 0.9839\n",
            "Epoch [28/250], Step [700/782], Loss: 0.6127\n",
            "Epoch [29/250], Step [0/782], Loss: 0.7829\n",
            "Epoch [29/250], Step [100/782], Loss: 0.6594\n",
            "Epoch [29/250], Step [200/782], Loss: 0.7296\n",
            "Epoch [29/250], Step [300/782], Loss: 0.7879\n",
            "Epoch [29/250], Step [400/782], Loss: 0.6501\n",
            "Epoch [29/250], Step [500/782], Loss: 0.7865\n",
            "Epoch [29/250], Step [600/782], Loss: 0.7270\n",
            "Epoch [29/250], Step [700/782], Loss: 0.8548\n",
            "Epoch [30/250], Step [0/782], Loss: 0.7044\n",
            "Epoch [30/250], Step [100/782], Loss: 0.7933\n",
            "Epoch [30/250], Step [200/782], Loss: 0.6612\n",
            "Epoch [30/250], Step [300/782], Loss: 1.2266\n",
            "Epoch [30/250], Step [400/782], Loss: 0.7296\n",
            "Epoch [30/250], Step [500/782], Loss: 1.0661\n",
            "Epoch [30/250], Step [600/782], Loss: 0.8067\n",
            "Epoch [30/250], Step [700/782], Loss: 0.9821\n",
            "Epoch [31/250], Step [0/782], Loss: 0.5890\n",
            "Epoch [31/250], Step [100/782], Loss: 0.7995\n",
            "Epoch [31/250], Step [200/782], Loss: 0.7802\n",
            "Epoch [31/250], Step [300/782], Loss: 0.9847\n",
            "Epoch [31/250], Step [400/782], Loss: 0.8698\n",
            "Epoch [31/250], Step [500/782], Loss: 0.7609\n",
            "Epoch [31/250], Step [600/782], Loss: 0.7512\n",
            "Epoch [31/250], Step [700/782], Loss: 0.8845\n",
            "Epoch [32/250], Step [0/782], Loss: 0.7596\n",
            "Epoch [32/250], Step [100/782], Loss: 0.8721\n",
            "Epoch [32/250], Step [200/782], Loss: 1.1228\n",
            "Epoch [32/250], Step [300/782], Loss: 0.7806\n",
            "Epoch [32/250], Step [400/782], Loss: 0.9132\n",
            "Epoch [32/250], Step [500/782], Loss: 0.6920\n",
            "Epoch [32/250], Step [600/782], Loss: 0.6549\n",
            "Epoch [32/250], Step [700/782], Loss: 0.8920\n",
            "Epoch [33/250], Step [0/782], Loss: 0.8175\n",
            "Epoch [33/250], Step [100/782], Loss: 0.9713\n",
            "Epoch [33/250], Step [200/782], Loss: 0.8782\n",
            "Epoch [33/250], Step [300/782], Loss: 0.8959\n",
            "Epoch [33/250], Step [400/782], Loss: 0.9766\n",
            "Epoch [33/250], Step [500/782], Loss: 0.8792\n",
            "Epoch [33/250], Step [600/782], Loss: 0.8231\n",
            "Epoch [33/250], Step [700/782], Loss: 0.7942\n",
            "Epoch [34/250], Step [0/782], Loss: 0.8978\n",
            "Epoch [34/250], Step [100/782], Loss: 0.6828\n",
            "Epoch [34/250], Step [200/782], Loss: 0.6376\n",
            "Epoch [34/250], Step [300/782], Loss: 0.5242\n",
            "Epoch [34/250], Step [400/782], Loss: 0.5909\n",
            "Epoch [34/250], Step [500/782], Loss: 0.6366\n",
            "Epoch [34/250], Step [600/782], Loss: 0.8107\n",
            "Epoch [34/250], Step [700/782], Loss: 0.9380\n",
            "Epoch [35/250], Step [0/782], Loss: 0.7904\n",
            "Epoch [35/250], Step [100/782], Loss: 0.7293\n",
            "Epoch [35/250], Step [200/782], Loss: 0.8413\n",
            "Epoch [35/250], Step [300/782], Loss: 0.7564\n",
            "Epoch [35/250], Step [400/782], Loss: 0.9885\n",
            "Epoch [35/250], Step [500/782], Loss: 0.7989\n",
            "Epoch [35/250], Step [600/782], Loss: 0.6444\n",
            "Epoch [35/250], Step [700/782], Loss: 0.6480\n",
            "Epoch [36/250], Step [0/782], Loss: 0.7858\n",
            "Epoch [36/250], Step [100/782], Loss: 0.6713\n",
            "Epoch [36/250], Step [200/782], Loss: 0.8269\n",
            "Epoch [36/250], Step [300/782], Loss: 0.8122\n",
            "Epoch [36/250], Step [400/782], Loss: 0.6804\n",
            "Epoch [36/250], Step [500/782], Loss: 0.7037\n",
            "Epoch [36/250], Step [600/782], Loss: 0.8315\n",
            "Epoch [36/250], Step [700/782], Loss: 0.5489\n",
            "Epoch [37/250], Step [0/782], Loss: 0.6168\n",
            "Epoch [37/250], Step [100/782], Loss: 0.8451\n",
            "Epoch [37/250], Step [200/782], Loss: 0.6808\n",
            "Epoch [37/250], Step [300/782], Loss: 0.5782\n",
            "Epoch [37/250], Step [400/782], Loss: 0.6937\n",
            "Epoch [37/250], Step [500/782], Loss: 0.6335\n",
            "Epoch [37/250], Step [600/782], Loss: 0.7346\n",
            "Epoch [37/250], Step [700/782], Loss: 0.4961\n",
            "Epoch [38/250], Step [0/782], Loss: 0.8487\n",
            "Epoch [38/250], Step [100/782], Loss: 0.6697\n",
            "Epoch [38/250], Step [200/782], Loss: 0.7622\n",
            "Epoch [38/250], Step [300/782], Loss: 0.6892\n",
            "Epoch [38/250], Step [400/782], Loss: 0.6041\n",
            "Epoch [38/250], Step [500/782], Loss: 0.7448\n",
            "Epoch [38/250], Step [600/782], Loss: 0.7119\n",
            "Epoch [38/250], Step [700/782], Loss: 0.7569\n",
            "Epoch [39/250], Step [0/782], Loss: 0.4664\n",
            "Epoch [39/250], Step [100/782], Loss: 0.5903\n",
            "Epoch [39/250], Step [200/782], Loss: 0.6644\n",
            "Epoch [39/250], Step [300/782], Loss: 0.5420\n",
            "Epoch [39/250], Step [400/782], Loss: 0.8668\n",
            "Epoch [39/250], Step [500/782], Loss: 0.7403\n",
            "Epoch [39/250], Step [600/782], Loss: 0.4833\n",
            "Epoch [39/250], Step [700/782], Loss: 0.5808\n",
            "Epoch [40/250], Step [0/782], Loss: 0.6316\n",
            "Epoch [40/250], Step [100/782], Loss: 0.7875\n",
            "Epoch [40/250], Step [200/782], Loss: 0.6162\n",
            "Epoch [40/250], Step [300/782], Loss: 0.6434\n",
            "Epoch [40/250], Step [400/782], Loss: 0.5187\n",
            "Epoch [40/250], Step [500/782], Loss: 0.5939\n",
            "Epoch [40/250], Step [600/782], Loss: 0.8128\n",
            "Epoch [40/250], Step [700/782], Loss: 0.7893\n",
            "Epoch [41/250], Step [0/782], Loss: 0.8348\n",
            "Epoch [41/250], Step [100/782], Loss: 0.6614\n",
            "Epoch [41/250], Step [200/782], Loss: 0.6790\n",
            "Epoch [41/250], Step [300/782], Loss: 0.5650\n",
            "Epoch [41/250], Step [400/782], Loss: 0.5319\n",
            "Epoch [41/250], Step [500/782], Loss: 0.5961\n",
            "Epoch [41/250], Step [600/782], Loss: 0.7353\n",
            "Epoch [41/250], Step [700/782], Loss: 0.5507\n",
            "Epoch [42/250], Step [0/782], Loss: 0.6482\n",
            "Epoch [42/250], Step [100/782], Loss: 0.5346\n",
            "Epoch [42/250], Step [200/782], Loss: 0.9351\n",
            "Epoch [42/250], Step [300/782], Loss: 0.4602\n",
            "Epoch [42/250], Step [400/782], Loss: 0.6843\n",
            "Epoch [42/250], Step [500/782], Loss: 0.7052\n",
            "Epoch [42/250], Step [600/782], Loss: 0.7129\n",
            "Epoch [42/250], Step [700/782], Loss: 0.5208\n",
            "Epoch [43/250], Step [0/782], Loss: 0.4719\n",
            "Epoch [43/250], Step [100/782], Loss: 0.8448\n",
            "Epoch [43/250], Step [200/782], Loss: 0.5316\n",
            "Epoch [43/250], Step [300/782], Loss: 0.8809\n",
            "Epoch [43/250], Step [400/782], Loss: 0.7026\n",
            "Epoch [43/250], Step [500/782], Loss: 1.0525\n",
            "Epoch [43/250], Step [600/782], Loss: 0.5705\n",
            "Epoch [43/250], Step [700/782], Loss: 0.6367\n",
            "Epoch [44/250], Step [0/782], Loss: 0.6767\n",
            "Epoch [44/250], Step [100/782], Loss: 0.6066\n",
            "Epoch [44/250], Step [200/782], Loss: 0.5000\n",
            "Epoch [44/250], Step [300/782], Loss: 0.5352\n",
            "Epoch [44/250], Step [400/782], Loss: 0.5457\n",
            "Epoch [44/250], Step [500/782], Loss: 0.4545\n",
            "Epoch [44/250], Step [600/782], Loss: 0.6906\n",
            "Epoch [44/250], Step [700/782], Loss: 0.6676\n",
            "Epoch [45/250], Step [0/782], Loss: 0.7900\n",
            "Epoch [45/250], Step [100/782], Loss: 0.5944\n",
            "Epoch [45/250], Step [200/782], Loss: 0.9261\n",
            "Epoch [45/250], Step [300/782], Loss: 0.3790\n",
            "Epoch [45/250], Step [400/782], Loss: 0.5307\n",
            "Epoch [45/250], Step [500/782], Loss: 0.5100\n",
            "Epoch [45/250], Step [600/782], Loss: 0.5122\n",
            "Epoch [45/250], Step [700/782], Loss: 0.6151\n",
            "Epoch [46/250], Step [0/782], Loss: 0.8784\n",
            "Epoch [46/250], Step [100/782], Loss: 0.6537\n",
            "Epoch [46/250], Step [200/782], Loss: 0.6252\n",
            "Epoch [46/250], Step [300/782], Loss: 0.5597\n",
            "Epoch [46/250], Step [400/782], Loss: 0.6430\n",
            "Epoch [46/250], Step [500/782], Loss: 0.6159\n",
            "Epoch [46/250], Step [600/782], Loss: 0.7013\n",
            "Epoch [46/250], Step [700/782], Loss: 0.7012\n",
            "Epoch [47/250], Step [0/782], Loss: 0.5508\n",
            "Epoch [47/250], Step [100/782], Loss: 0.6034\n",
            "Epoch [47/250], Step [200/782], Loss: 0.7246\n",
            "Epoch [47/250], Step [300/782], Loss: 0.5385\n",
            "Epoch [47/250], Step [400/782], Loss: 0.5945\n",
            "Epoch [47/250], Step [500/782], Loss: 0.6711\n",
            "Epoch [47/250], Step [600/782], Loss: 0.6421\n",
            "Epoch [47/250], Step [700/782], Loss: 0.8965\n",
            "Epoch [48/250], Step [0/782], Loss: 0.5382\n",
            "Epoch [48/250], Step [100/782], Loss: 0.5695\n",
            "Epoch [48/250], Step [200/782], Loss: 0.5737\n",
            "Epoch [48/250], Step [300/782], Loss: 0.4575\n",
            "Epoch [48/250], Step [400/782], Loss: 0.7021\n",
            "Epoch [48/250], Step [500/782], Loss: 0.4470\n",
            "Epoch [48/250], Step [600/782], Loss: 0.7318\n",
            "Epoch [48/250], Step [700/782], Loss: 0.7179\n",
            "Epoch [49/250], Step [0/782], Loss: 0.6458\n",
            "Epoch [49/250], Step [100/782], Loss: 0.6102\n",
            "Epoch [49/250], Step [200/782], Loss: 0.4121\n",
            "Epoch [49/250], Step [300/782], Loss: 0.6941\n",
            "Epoch [49/250], Step [400/782], Loss: 0.5823\n",
            "Epoch [49/250], Step [500/782], Loss: 0.5721\n",
            "Epoch [49/250], Step [600/782], Loss: 0.7608\n",
            "Epoch [49/250], Step [700/782], Loss: 0.6029\n",
            "Epoch [50/250], Step [0/782], Loss: 0.6464\n",
            "Epoch [50/250], Step [100/782], Loss: 0.5563\n",
            "Epoch [50/250], Step [200/782], Loss: 0.5044\n",
            "Epoch [50/250], Step [300/782], Loss: 0.4423\n",
            "Epoch [50/250], Step [400/782], Loss: 0.6692\n",
            "Epoch [50/250], Step [500/782], Loss: 0.5162\n",
            "Epoch [50/250], Step [600/782], Loss: 0.6905\n",
            "Epoch [50/250], Step [700/782], Loss: 0.4403\n",
            "Epoch [51/250], Step [0/782], Loss: 0.5853\n",
            "Epoch [51/250], Step [100/782], Loss: 0.4801\n",
            "Epoch [51/250], Step [200/782], Loss: 0.7034\n",
            "Epoch [51/250], Step [300/782], Loss: 0.5077\n",
            "Epoch [51/250], Step [400/782], Loss: 0.6899\n",
            "Epoch [51/250], Step [500/782], Loss: 0.4274\n",
            "Epoch [51/250], Step [600/782], Loss: 0.4758\n",
            "Epoch [51/250], Step [700/782], Loss: 0.6033\n",
            "Epoch [52/250], Step [0/782], Loss: 0.6527\n",
            "Epoch [52/250], Step [100/782], Loss: 0.5039\n",
            "Epoch [52/250], Step [200/782], Loss: 0.3755\n",
            "Epoch [52/250], Step [300/782], Loss: 0.3835\n",
            "Epoch [52/250], Step [400/782], Loss: 0.6996\n",
            "Epoch [52/250], Step [500/782], Loss: 0.5212\n",
            "Epoch [52/250], Step [600/782], Loss: 0.3542\n",
            "Epoch [52/250], Step [700/782], Loss: 0.4100\n",
            "Epoch [53/250], Step [0/782], Loss: 0.4779\n",
            "Epoch [53/250], Step [100/782], Loss: 0.3907\n",
            "Epoch [53/250], Step [200/782], Loss: 0.5909\n",
            "Epoch [53/250], Step [300/782], Loss: 0.5396\n",
            "Epoch [53/250], Step [400/782], Loss: 0.4261\n",
            "Epoch [53/250], Step [500/782], Loss: 0.6946\n",
            "Epoch [53/250], Step [600/782], Loss: 0.5722\n",
            "Epoch [53/250], Step [700/782], Loss: 0.8254\n",
            "Epoch [54/250], Step [0/782], Loss: 0.5122\n",
            "Epoch [54/250], Step [100/782], Loss: 0.7545\n",
            "Epoch [54/250], Step [200/782], Loss: 0.4944\n",
            "Epoch [54/250], Step [300/782], Loss: 0.6423\n",
            "Epoch [54/250], Step [400/782], Loss: 0.4827\n",
            "Epoch [54/250], Step [500/782], Loss: 0.5438\n",
            "Epoch [54/250], Step [600/782], Loss: 0.5753\n",
            "Epoch [54/250], Step [700/782], Loss: 0.5052\n",
            "Epoch [55/250], Step [0/782], Loss: 0.5416\n",
            "Epoch [55/250], Step [100/782], Loss: 0.7262\n",
            "Epoch [55/250], Step [200/782], Loss: 0.4342\n",
            "Epoch [55/250], Step [300/782], Loss: 0.4950\n",
            "Epoch [55/250], Step [400/782], Loss: 0.6644\n",
            "Epoch [55/250], Step [500/782], Loss: 0.5154\n",
            "Epoch [55/250], Step [600/782], Loss: 0.5481\n",
            "Epoch [55/250], Step [700/782], Loss: 0.4910\n",
            "Epoch [56/250], Step [0/782], Loss: 0.3647\n",
            "Epoch [56/250], Step [100/782], Loss: 0.4835\n",
            "Epoch [56/250], Step [200/782], Loss: 0.4891\n",
            "Epoch [56/250], Step [300/782], Loss: 0.3462\n",
            "Epoch [56/250], Step [400/782], Loss: 0.3515\n",
            "Epoch [56/250], Step [500/782], Loss: 0.5025\n",
            "Epoch [56/250], Step [600/782], Loss: 0.5208\n",
            "Epoch [56/250], Step [700/782], Loss: 0.4622\n",
            "Epoch [57/250], Step [0/782], Loss: 0.5137\n",
            "Epoch [57/250], Step [100/782], Loss: 0.5784\n",
            "Epoch [57/250], Step [200/782], Loss: 1.0452\n",
            "Epoch [57/250], Step [300/782], Loss: 0.3514\n",
            "Epoch [57/250], Step [400/782], Loss: 0.5521\n",
            "Epoch [57/250], Step [500/782], Loss: 0.3765\n",
            "Epoch [57/250], Step [600/782], Loss: 0.5217\n",
            "Epoch [57/250], Step [700/782], Loss: 0.6032\n",
            "Epoch [58/250], Step [0/782], Loss: 0.5710\n",
            "Epoch [58/250], Step [100/782], Loss: 0.3596\n",
            "Epoch [58/250], Step [200/782], Loss: 0.4079\n",
            "Epoch [58/250], Step [300/782], Loss: 0.4965\n",
            "Epoch [58/250], Step [400/782], Loss: 0.4673\n",
            "Epoch [58/250], Step [500/782], Loss: 0.5650\n",
            "Epoch [58/250], Step [600/782], Loss: 0.4863\n",
            "Epoch [58/250], Step [700/782], Loss: 0.5338\n",
            "Epoch [59/250], Step [0/782], Loss: 0.6480\n",
            "Epoch [59/250], Step [100/782], Loss: 0.6385\n",
            "Epoch [59/250], Step [200/782], Loss: 0.4375\n",
            "Epoch [59/250], Step [300/782], Loss: 0.3794\n",
            "Epoch [59/250], Step [400/782], Loss: 0.3559\n",
            "Epoch [59/250], Step [500/782], Loss: 0.4620\n",
            "Epoch [59/250], Step [600/782], Loss: 0.5178\n",
            "Epoch [59/250], Step [700/782], Loss: 0.3706\n",
            "Epoch [60/250], Step [0/782], Loss: 0.5863\n",
            "Epoch [60/250], Step [100/782], Loss: 0.4103\n",
            "Epoch [60/250], Step [200/782], Loss: 0.6877\n",
            "Epoch [60/250], Step [300/782], Loss: 0.5102\n",
            "Epoch [60/250], Step [400/782], Loss: 0.5643\n",
            "Epoch [60/250], Step [500/782], Loss: 0.5211\n",
            "Epoch [60/250], Step [600/782], Loss: 0.3988\n",
            "Epoch [60/250], Step [700/782], Loss: 0.4741\n",
            "Epoch [61/250], Step [0/782], Loss: 0.5493\n",
            "Epoch [61/250], Step [100/782], Loss: 0.4324\n",
            "Epoch [61/250], Step [200/782], Loss: 0.4771\n",
            "Epoch [61/250], Step [300/782], Loss: 0.4506\n",
            "Epoch [61/250], Step [400/782], Loss: 0.4456\n",
            "Epoch [61/250], Step [500/782], Loss: 0.4470\n",
            "Epoch [61/250], Step [600/782], Loss: 0.4962\n",
            "Epoch [61/250], Step [700/782], Loss: 0.6940\n",
            "Epoch [62/250], Step [0/782], Loss: 0.5020\n",
            "Epoch [62/250], Step [100/782], Loss: 0.4345\n",
            "Epoch [62/250], Step [200/782], Loss: 0.3039\n",
            "Epoch [62/250], Step [300/782], Loss: 0.4837\n",
            "Epoch [62/250], Step [400/782], Loss: 0.3817\n",
            "Epoch [62/250], Step [500/782], Loss: 0.6419\n",
            "Epoch [62/250], Step [600/782], Loss: 0.4637\n",
            "Epoch [62/250], Step [700/782], Loss: 0.4462\n",
            "Epoch [63/250], Step [0/782], Loss: 0.5634\n",
            "Epoch [63/250], Step [100/782], Loss: 0.6230\n",
            "Epoch [63/250], Step [200/782], Loss: 0.5345\n",
            "Epoch [63/250], Step [300/782], Loss: 0.4394\n",
            "Epoch [63/250], Step [400/782], Loss: 0.2911\n",
            "Epoch [63/250], Step [500/782], Loss: 0.4765\n",
            "Epoch [63/250], Step [600/782], Loss: 0.5054\n",
            "Epoch [63/250], Step [700/782], Loss: 0.4202\n",
            "Epoch [64/250], Step [0/782], Loss: 0.5846\n",
            "Epoch [64/250], Step [100/782], Loss: 0.5624\n",
            "Epoch [64/250], Step [200/782], Loss: 0.5472\n",
            "Epoch [64/250], Step [300/782], Loss: 0.4870\n",
            "Epoch [64/250], Step [400/782], Loss: 0.3728\n",
            "Epoch [64/250], Step [500/782], Loss: 0.5065\n",
            "Epoch [64/250], Step [600/782], Loss: 0.3812\n",
            "Epoch [64/250], Step [700/782], Loss: 0.5019\n",
            "Epoch [65/250], Step [0/782], Loss: 0.3713\n",
            "Epoch [65/250], Step [100/782], Loss: 0.5255\n",
            "Epoch [65/250], Step [200/782], Loss: 0.5564\n",
            "Epoch [65/250], Step [300/782], Loss: 0.5446\n",
            "Epoch [65/250], Step [400/782], Loss: 0.3775\n",
            "Epoch [65/250], Step [500/782], Loss: 0.6407\n",
            "Epoch [65/250], Step [600/782], Loss: 0.4049\n",
            "Epoch [65/250], Step [700/782], Loss: 0.7792\n",
            "Epoch [66/250], Step [0/782], Loss: 0.3743\n",
            "Epoch [66/250], Step [100/782], Loss: 0.4482\n",
            "Epoch [66/250], Step [200/782], Loss: 0.3612\n",
            "Epoch [66/250], Step [300/782], Loss: 0.3029\n",
            "Epoch [66/250], Step [400/782], Loss: 0.5838\n",
            "Epoch [66/250], Step [500/782], Loss: 0.3607\n",
            "Epoch [66/250], Step [600/782], Loss: 0.5911\n",
            "Epoch [66/250], Step [700/782], Loss: 0.6655\n",
            "Epoch [67/250], Step [0/782], Loss: 0.4840\n",
            "Epoch [67/250], Step [100/782], Loss: 0.4648\n",
            "Epoch [67/250], Step [200/782], Loss: 0.3669\n",
            "Epoch [67/250], Step [300/782], Loss: 0.4310\n",
            "Epoch [67/250], Step [400/782], Loss: 0.4697\n",
            "Epoch [67/250], Step [500/782], Loss: 0.3978\n",
            "Epoch [67/250], Step [600/782], Loss: 0.5283\n",
            "Epoch [67/250], Step [700/782], Loss: 0.4458\n",
            "Epoch [68/250], Step [0/782], Loss: 0.3709\n",
            "Epoch [68/250], Step [100/782], Loss: 0.5520\n",
            "Epoch [68/250], Step [200/782], Loss: 0.4478\n",
            "Epoch [68/250], Step [300/782], Loss: 0.4794\n",
            "Epoch [68/250], Step [400/782], Loss: 0.3466\n",
            "Epoch [68/250], Step [500/782], Loss: 0.5464\n",
            "Epoch [68/250], Step [600/782], Loss: 0.6239\n",
            "Epoch [68/250], Step [700/782], Loss: 0.4642\n",
            "Epoch [69/250], Step [0/782], Loss: 0.5276\n",
            "Epoch [69/250], Step [100/782], Loss: 0.2537\n",
            "Epoch [69/250], Step [200/782], Loss: 0.4113\n",
            "Epoch [69/250], Step [300/782], Loss: 0.4341\n",
            "Epoch [69/250], Step [400/782], Loss: 0.7109\n",
            "Epoch [69/250], Step [500/782], Loss: 0.3597\n",
            "Epoch [69/250], Step [600/782], Loss: 0.2685\n",
            "Epoch [69/250], Step [700/782], Loss: 0.4360\n",
            "Epoch [70/250], Step [0/782], Loss: 0.4012\n",
            "Epoch [70/250], Step [100/782], Loss: 0.4968\n",
            "Epoch [70/250], Step [200/782], Loss: 0.2211\n",
            "Epoch [70/250], Step [300/782], Loss: 0.4207\n",
            "Epoch [70/250], Step [400/782], Loss: 0.4181\n",
            "Epoch [70/250], Step [500/782], Loss: 0.4861\n",
            "Epoch [70/250], Step [600/782], Loss: 0.3102\n",
            "Epoch [70/250], Step [700/782], Loss: 0.4293\n",
            "Epoch [71/250], Step [0/782], Loss: 0.4722\n",
            "Epoch [71/250], Step [100/782], Loss: 0.4947\n",
            "Epoch [71/250], Step [200/782], Loss: 0.3895\n",
            "Epoch [71/250], Step [300/782], Loss: 0.3851\n",
            "Epoch [71/250], Step [400/782], Loss: 0.3160\n",
            "Epoch [71/250], Step [500/782], Loss: 0.4397\n",
            "Epoch [71/250], Step [600/782], Loss: 0.3362\n",
            "Epoch [71/250], Step [700/782], Loss: 0.2767\n",
            "Epoch [72/250], Step [0/782], Loss: 0.6237\n",
            "Epoch [72/250], Step [100/782], Loss: 0.5293\n",
            "Epoch [72/250], Step [200/782], Loss: 0.2452\n",
            "Epoch [72/250], Step [300/782], Loss: 0.4095\n",
            "Epoch [72/250], Step [400/782], Loss: 0.3467\n",
            "Epoch [72/250], Step [500/782], Loss: 0.5318\n",
            "Epoch [72/250], Step [600/782], Loss: 0.3774\n",
            "Epoch [72/250], Step [700/782], Loss: 0.5074\n",
            "Epoch [73/250], Step [0/782], Loss: 0.2443\n",
            "Epoch [73/250], Step [100/782], Loss: 0.6630\n",
            "Epoch [73/250], Step [200/782], Loss: 0.2636\n",
            "Epoch [73/250], Step [300/782], Loss: 0.4939\n",
            "Epoch [73/250], Step [400/782], Loss: 0.3693\n",
            "Epoch [73/250], Step [500/782], Loss: 0.3803\n",
            "Epoch [73/250], Step [600/782], Loss: 0.4034\n",
            "Epoch [73/250], Step [700/782], Loss: 0.5107\n",
            "Epoch [74/250], Step [0/782], Loss: 0.4117\n",
            "Epoch [74/250], Step [100/782], Loss: 0.2253\n",
            "Epoch [74/250], Step [200/782], Loss: 0.4966\n",
            "Epoch [74/250], Step [300/782], Loss: 0.4083\n",
            "Epoch [74/250], Step [400/782], Loss: 0.3660\n",
            "Epoch [74/250], Step [500/782], Loss: 0.6306\n",
            "Epoch [74/250], Step [600/782], Loss: 0.4596\n",
            "Epoch [74/250], Step [700/782], Loss: 0.4634\n",
            "Epoch [75/250], Step [0/782], Loss: 0.5501\n",
            "Epoch [75/250], Step [100/782], Loss: 0.3832\n",
            "Epoch [75/250], Step [200/782], Loss: 0.3922\n",
            "Epoch [75/250], Step [300/782], Loss: 0.3433\n",
            "Epoch [75/250], Step [400/782], Loss: 0.4463\n",
            "Epoch [75/250], Step [500/782], Loss: 0.4409\n",
            "Epoch [75/250], Step [600/782], Loss: 0.4334\n",
            "Epoch [75/250], Step [700/782], Loss: 0.5408\n",
            "Epoch [76/250], Step [0/782], Loss: 0.2849\n",
            "Epoch [76/250], Step [100/782], Loss: 0.3126\n",
            "Epoch [76/250], Step [200/782], Loss: 0.3749\n",
            "Epoch [76/250], Step [300/782], Loss: 0.5391\n",
            "Epoch [76/250], Step [400/782], Loss: 0.4695\n",
            "Epoch [76/250], Step [500/782], Loss: 0.4101\n",
            "Epoch [76/250], Step [600/782], Loss: 0.4661\n",
            "Epoch [76/250], Step [700/782], Loss: 0.4860\n",
            "Epoch [77/250], Step [0/782], Loss: 0.3761\n",
            "Epoch [77/250], Step [100/782], Loss: 0.2726\n",
            "Epoch [77/250], Step [200/782], Loss: 0.4388\n",
            "Epoch [77/250], Step [300/782], Loss: 0.6268\n",
            "Epoch [77/250], Step [400/782], Loss: 0.2993\n",
            "Epoch [77/250], Step [500/782], Loss: 0.5265\n",
            "Epoch [77/250], Step [600/782], Loss: 0.3190\n",
            "Epoch [77/250], Step [700/782], Loss: 0.3116\n",
            "Epoch [78/250], Step [0/782], Loss: 0.3100\n",
            "Epoch [78/250], Step [100/782], Loss: 0.3044\n",
            "Epoch [78/250], Step [200/782], Loss: 0.2428\n",
            "Epoch [78/250], Step [300/782], Loss: 0.3517\n",
            "Epoch [78/250], Step [400/782], Loss: 0.2825\n",
            "Epoch [78/250], Step [500/782], Loss: 0.2879\n",
            "Epoch [78/250], Step [600/782], Loss: 0.3716\n",
            "Epoch [78/250], Step [700/782], Loss: 0.3648\n",
            "Epoch [79/250], Step [0/782], Loss: 0.3668\n",
            "Epoch [79/250], Step [100/782], Loss: 0.5048\n",
            "Epoch [79/250], Step [200/782], Loss: 0.3071\n",
            "Epoch [79/250], Step [300/782], Loss: 0.4783\n",
            "Epoch [79/250], Step [400/782], Loss: 0.3392\n",
            "Epoch [79/250], Step [500/782], Loss: 0.5881\n",
            "Epoch [79/250], Step [600/782], Loss: 0.4769\n",
            "Epoch [79/250], Step [700/782], Loss: 0.3393\n",
            "Epoch [80/250], Step [0/782], Loss: 0.3773\n",
            "Epoch [80/250], Step [100/782], Loss: 0.5800\n",
            "Epoch [80/250], Step [200/782], Loss: 0.2778\n",
            "Epoch [80/250], Step [300/782], Loss: 0.3582\n",
            "Epoch [80/250], Step [400/782], Loss: 0.3714\n",
            "Epoch [80/250], Step [500/782], Loss: 0.2137\n",
            "Epoch [80/250], Step [600/782], Loss: 0.2188\n",
            "Epoch [80/250], Step [700/782], Loss: 0.3411\n",
            "Epoch [81/250], Step [0/782], Loss: 0.5059\n",
            "Epoch [81/250], Step [100/782], Loss: 0.2969\n",
            "Epoch [81/250], Step [200/782], Loss: 0.2188\n",
            "Epoch [81/250], Step [300/782], Loss: 0.2404\n",
            "Epoch [81/250], Step [400/782], Loss: 0.3438\n",
            "Epoch [81/250], Step [500/782], Loss: 0.3987\n",
            "Epoch [81/250], Step [600/782], Loss: 0.2367\n",
            "Epoch [81/250], Step [700/782], Loss: 0.3140\n",
            "Epoch [82/250], Step [0/782], Loss: 0.2882\n",
            "Epoch [82/250], Step [100/782], Loss: 0.4368\n",
            "Epoch [82/250], Step [200/782], Loss: 0.3778\n",
            "Epoch [82/250], Step [300/782], Loss: 0.1650\n",
            "Epoch [82/250], Step [400/782], Loss: 0.2535\n",
            "Epoch [82/250], Step [500/782], Loss: 0.2917\n",
            "Epoch [82/250], Step [600/782], Loss: 0.3364\n",
            "Epoch [82/250], Step [700/782], Loss: 0.2657\n",
            "Epoch [83/250], Step [0/782], Loss: 0.1824\n",
            "Epoch [83/250], Step [100/782], Loss: 0.3072\n",
            "Epoch [83/250], Step [200/782], Loss: 0.4577\n",
            "Epoch [83/250], Step [300/782], Loss: 0.4676\n",
            "Epoch [83/250], Step [400/782], Loss: 0.3403\n",
            "Epoch [83/250], Step [500/782], Loss: 0.2603\n",
            "Epoch [83/250], Step [600/782], Loss: 0.2844\n",
            "Epoch [83/250], Step [700/782], Loss: 0.4394\n",
            "Epoch [84/250], Step [0/782], Loss: 0.3282\n",
            "Epoch [84/250], Step [100/782], Loss: 0.3442\n",
            "Epoch [84/250], Step [200/782], Loss: 0.3919\n",
            "Epoch [84/250], Step [300/782], Loss: 0.2746\n",
            "Epoch [84/250], Step [400/782], Loss: 0.4025\n",
            "Epoch [84/250], Step [500/782], Loss: 0.2826\n",
            "Epoch [84/250], Step [600/782], Loss: 0.4411\n",
            "Epoch [84/250], Step [700/782], Loss: 0.3459\n",
            "Epoch [85/250], Step [0/782], Loss: 0.4197\n",
            "Epoch [85/250], Step [100/782], Loss: 0.3113\n",
            "Epoch [85/250], Step [200/782], Loss: 0.2471\n",
            "Epoch [85/250], Step [300/782], Loss: 0.3320\n",
            "Epoch [85/250], Step [400/782], Loss: 0.3031\n",
            "Epoch [85/250], Step [500/782], Loss: 0.3497\n",
            "Epoch [85/250], Step [600/782], Loss: 0.3664\n",
            "Epoch [85/250], Step [700/782], Loss: 0.2325\n",
            "Epoch [86/250], Step [0/782], Loss: 0.5273\n",
            "Epoch [86/250], Step [100/782], Loss: 0.4016\n",
            "Epoch [86/250], Step [200/782], Loss: 0.3099\n",
            "Epoch [86/250], Step [300/782], Loss: 0.4080\n",
            "Epoch [86/250], Step [400/782], Loss: 0.4887\n",
            "Epoch [86/250], Step [500/782], Loss: 0.3840\n",
            "Epoch [86/250], Step [600/782], Loss: 0.4060\n",
            "Epoch [86/250], Step [700/782], Loss: 0.2807\n",
            "Epoch [87/250], Step [0/782], Loss: 0.3649\n",
            "Epoch [87/250], Step [100/782], Loss: 0.4274\n",
            "Epoch [87/250], Step [200/782], Loss: 0.3132\n",
            "Epoch [87/250], Step [300/782], Loss: 0.3262\n",
            "Epoch [87/250], Step [400/782], Loss: 0.3553\n",
            "Epoch [87/250], Step [500/782], Loss: 0.3610\n",
            "Epoch [87/250], Step [600/782], Loss: 0.2884\n",
            "Epoch [87/250], Step [700/782], Loss: 0.3192\n",
            "Epoch [88/250], Step [0/782], Loss: 0.2368\n",
            "Epoch [88/250], Step [100/782], Loss: 0.3340\n",
            "Epoch [88/250], Step [200/782], Loss: 0.3290\n",
            "Epoch [88/250], Step [300/782], Loss: 0.4491\n",
            "Epoch [88/250], Step [400/782], Loss: 0.2454\n",
            "Epoch [88/250], Step [500/782], Loss: 0.2768\n",
            "Epoch [88/250], Step [600/782], Loss: 0.4095\n",
            "Epoch [88/250], Step [700/782], Loss: 0.2777\n",
            "Epoch [89/250], Step [0/782], Loss: 0.2184\n",
            "Epoch [89/250], Step [100/782], Loss: 0.2957\n",
            "Epoch [89/250], Step [200/782], Loss: 0.4264\n",
            "Epoch [89/250], Step [300/782], Loss: 0.2433\n",
            "Epoch [89/250], Step [400/782], Loss: 0.5329\n",
            "Epoch [89/250], Step [500/782], Loss: 0.4728\n",
            "Epoch [89/250], Step [600/782], Loss: 0.2625\n",
            "Epoch [89/250], Step [700/782], Loss: 0.2224\n",
            "Epoch [90/250], Step [0/782], Loss: 0.1895\n",
            "Epoch [90/250], Step [100/782], Loss: 0.3138\n",
            "Epoch [90/250], Step [200/782], Loss: 0.2327\n",
            "Epoch [90/250], Step [300/782], Loss: 0.2772\n",
            "Epoch [90/250], Step [400/782], Loss: 0.3274\n",
            "Epoch [90/250], Step [500/782], Loss: 0.2249\n",
            "Epoch [90/250], Step [600/782], Loss: 0.4557\n",
            "Epoch [90/250], Step [700/782], Loss: 0.4077\n",
            "Epoch [91/250], Step [0/782], Loss: 0.4425\n",
            "Epoch [91/250], Step [100/782], Loss: 0.3538\n",
            "Epoch [91/250], Step [200/782], Loss: 0.3371\n",
            "Epoch [91/250], Step [300/782], Loss: 0.3866\n",
            "Epoch [91/250], Step [400/782], Loss: 0.3158\n",
            "Epoch [91/250], Step [500/782], Loss: 0.3192\n",
            "Epoch [91/250], Step [600/782], Loss: 0.3177\n",
            "Epoch [91/250], Step [700/782], Loss: 0.3342\n",
            "Epoch [92/250], Step [0/782], Loss: 0.3420\n",
            "Epoch [92/250], Step [100/782], Loss: 0.1499\n",
            "Epoch [92/250], Step [200/782], Loss: 0.2273\n",
            "Epoch [92/250], Step [300/782], Loss: 0.4030\n",
            "Epoch [92/250], Step [400/782], Loss: 0.0994\n",
            "Epoch [92/250], Step [500/782], Loss: 0.2966\n",
            "Epoch [92/250], Step [600/782], Loss: 0.3526\n",
            "Epoch [92/250], Step [700/782], Loss: 0.3851\n",
            "Epoch [93/250], Step [0/782], Loss: 0.3317\n",
            "Epoch [93/250], Step [100/782], Loss: 0.6311\n",
            "Epoch [93/250], Step [200/782], Loss: 0.2573\n",
            "Epoch [93/250], Step [300/782], Loss: 0.3773\n",
            "Epoch [93/250], Step [400/782], Loss: 0.2430\n",
            "Epoch [93/250], Step [500/782], Loss: 0.2983\n",
            "Epoch [93/250], Step [600/782], Loss: 0.4910\n",
            "Epoch [93/250], Step [700/782], Loss: 0.1617\n",
            "Epoch [94/250], Step [0/782], Loss: 0.3277\n",
            "Epoch [94/250], Step [100/782], Loss: 0.1962\n",
            "Epoch [94/250], Step [200/782], Loss: 0.4231\n",
            "Epoch [94/250], Step [300/782], Loss: 0.3685\n",
            "Epoch [94/250], Step [400/782], Loss: 0.2677\n",
            "Epoch [94/250], Step [500/782], Loss: 0.4210\n",
            "Epoch [94/250], Step [600/782], Loss: 0.3068\n",
            "Epoch [94/250], Step [700/782], Loss: 0.3245\n",
            "Epoch [95/250], Step [0/782], Loss: 0.5483\n",
            "Epoch [95/250], Step [100/782], Loss: 0.3163\n",
            "Epoch [95/250], Step [200/782], Loss: 0.4317\n",
            "Epoch [95/250], Step [300/782], Loss: 0.3345\n",
            "Epoch [95/250], Step [400/782], Loss: 0.1907\n",
            "Epoch [95/250], Step [500/782], Loss: 0.1608\n",
            "Epoch [95/250], Step [600/782], Loss: 0.3342\n",
            "Epoch [95/250], Step [700/782], Loss: 0.2593\n",
            "Epoch [96/250], Step [0/782], Loss: 0.3043\n",
            "Epoch [96/250], Step [100/782], Loss: 0.2795\n",
            "Epoch [96/250], Step [200/782], Loss: 0.2363\n",
            "Epoch [96/250], Step [300/782], Loss: 0.3567\n",
            "Epoch [96/250], Step [400/782], Loss: 0.3035\n",
            "Epoch [96/250], Step [500/782], Loss: 0.3253\n",
            "Epoch [96/250], Step [600/782], Loss: 0.2477\n",
            "Epoch [96/250], Step [700/782], Loss: 0.4967\n",
            "Epoch [97/250], Step [0/782], Loss: 0.2420\n",
            "Epoch [97/250], Step [100/782], Loss: 0.2606\n",
            "Epoch [97/250], Step [200/782], Loss: 0.4065\n",
            "Epoch [97/250], Step [300/782], Loss: 0.3782\n",
            "Epoch [97/250], Step [400/782], Loss: 0.3066\n",
            "Epoch [97/250], Step [500/782], Loss: 0.3934\n",
            "Epoch [97/250], Step [600/782], Loss: 0.3881\n",
            "Epoch [97/250], Step [700/782], Loss: 0.3233\n",
            "Epoch [98/250], Step [0/782], Loss: 0.1958\n",
            "Epoch [98/250], Step [100/782], Loss: 0.3791\n",
            "Epoch [98/250], Step [200/782], Loss: 0.2760\n",
            "Epoch [98/250], Step [300/782], Loss: 0.2276\n",
            "Epoch [98/250], Step [400/782], Loss: 0.1401\n",
            "Epoch [98/250], Step [500/782], Loss: 0.3225\n",
            "Epoch [98/250], Step [600/782], Loss: 0.3553\n",
            "Epoch [98/250], Step [700/782], Loss: 0.3251\n",
            "Epoch [99/250], Step [0/782], Loss: 0.3859\n",
            "Epoch [99/250], Step [100/782], Loss: 0.1991\n",
            "Epoch [99/250], Step [200/782], Loss: 0.3962\n",
            "Epoch [99/250], Step [300/782], Loss: 0.1851\n",
            "Epoch [99/250], Step [400/782], Loss: 0.2802\n",
            "Epoch [99/250], Step [500/782], Loss: 0.2931\n",
            "Epoch [99/250], Step [600/782], Loss: 0.3060\n",
            "Epoch [99/250], Step [700/782], Loss: 0.2671\n",
            "Epoch [100/250], Step [0/782], Loss: 0.3076\n",
            "Epoch [100/250], Step [100/782], Loss: 0.2413\n",
            "Epoch [100/250], Step [200/782], Loss: 0.3479\n",
            "Epoch [100/250], Step [300/782], Loss: 0.3397\n",
            "Epoch [100/250], Step [400/782], Loss: 0.1925\n",
            "Epoch [100/250], Step [500/782], Loss: 0.2638\n",
            "Epoch [100/250], Step [600/782], Loss: 0.2762\n",
            "Epoch [100/250], Step [700/782], Loss: 0.2625\n",
            "Epoch [101/250], Step [0/782], Loss: 0.2593\n",
            "Epoch [101/250], Step [100/782], Loss: 0.3605\n",
            "Epoch [101/250], Step [200/782], Loss: 0.2058\n",
            "Epoch [101/250], Step [300/782], Loss: 0.3129\n",
            "Epoch [101/250], Step [400/782], Loss: 0.4062\n",
            "Epoch [101/250], Step [500/782], Loss: 0.2328\n",
            "Epoch [101/250], Step [600/782], Loss: 0.3502\n",
            "Epoch [101/250], Step [700/782], Loss: 0.3064\n",
            "Epoch [102/250], Step [0/782], Loss: 0.3091\n",
            "Epoch [102/250], Step [100/782], Loss: 0.3787\n",
            "Epoch [102/250], Step [200/782], Loss: 0.4895\n",
            "Epoch [102/250], Step [300/782], Loss: 0.3480\n",
            "Epoch [102/250], Step [400/782], Loss: 0.2520\n",
            "Epoch [102/250], Step [500/782], Loss: 0.3494\n",
            "Epoch [102/250], Step [600/782], Loss: 0.1919\n",
            "Epoch [102/250], Step [700/782], Loss: 0.2568\n",
            "Epoch [103/250], Step [0/782], Loss: 0.3722\n",
            "Epoch [103/250], Step [100/782], Loss: 0.3071\n",
            "Epoch [103/250], Step [200/782], Loss: 0.2476\n",
            "Epoch [103/250], Step [300/782], Loss: 0.3261\n",
            "Epoch [103/250], Step [400/782], Loss: 0.3061\n",
            "Epoch [103/250], Step [500/782], Loss: 0.2287\n",
            "Epoch [103/250], Step [600/782], Loss: 0.2964\n",
            "Epoch [103/250], Step [700/782], Loss: 0.2089\n",
            "Epoch [104/250], Step [0/782], Loss: 0.1684\n",
            "Epoch [104/250], Step [100/782], Loss: 0.1587\n",
            "Epoch [104/250], Step [200/782], Loss: 0.1697\n",
            "Epoch [104/250], Step [300/782], Loss: 0.4068\n",
            "Epoch [104/250], Step [400/782], Loss: 0.3576\n",
            "Epoch [104/250], Step [500/782], Loss: 0.3088\n",
            "Epoch [104/250], Step [600/782], Loss: 0.1462\n",
            "Epoch [104/250], Step [700/782], Loss: 0.3084\n",
            "Epoch [105/250], Step [0/782], Loss: 0.3326\n",
            "Epoch [105/250], Step [100/782], Loss: 0.3630\n",
            "Epoch [105/250], Step [200/782], Loss: 0.1877\n",
            "Epoch [105/250], Step [300/782], Loss: 0.2401\n",
            "Epoch [105/250], Step [400/782], Loss: 0.1110\n",
            "Epoch [105/250], Step [500/782], Loss: 0.2097\n",
            "Epoch [105/250], Step [600/782], Loss: 0.4056\n",
            "Epoch [105/250], Step [700/782], Loss: 0.3059\n",
            "Epoch [106/250], Step [0/782], Loss: 0.1721\n",
            "Epoch [106/250], Step [100/782], Loss: 0.2152\n",
            "Epoch [106/250], Step [200/782], Loss: 0.2263\n",
            "Epoch [106/250], Step [300/782], Loss: 0.3319\n",
            "Epoch [106/250], Step [400/782], Loss: 0.1492\n",
            "Epoch [106/250], Step [500/782], Loss: 0.1723\n",
            "Epoch [106/250], Step [600/782], Loss: 0.4504\n",
            "Epoch [106/250], Step [700/782], Loss: 0.2231\n",
            "Epoch [107/250], Step [0/782], Loss: 0.3051\n",
            "Epoch [107/250], Step [100/782], Loss: 0.2625\n",
            "Epoch [107/250], Step [200/782], Loss: 0.2000\n",
            "Epoch [107/250], Step [300/782], Loss: 0.5197\n",
            "Epoch [107/250], Step [400/782], Loss: 0.2636\n",
            "Epoch [107/250], Step [500/782], Loss: 0.1738\n",
            "Epoch [107/250], Step [600/782], Loss: 0.1942\n",
            "Epoch [107/250], Step [700/782], Loss: 0.1742\n",
            "Epoch [108/250], Step [0/782], Loss: 0.3754\n",
            "Epoch [108/250], Step [100/782], Loss: 0.2605\n",
            "Epoch [108/250], Step [200/782], Loss: 0.1739\n",
            "Epoch [108/250], Step [300/782], Loss: 0.1822\n",
            "Epoch [108/250], Step [400/782], Loss: 0.1940\n",
            "Epoch [108/250], Step [500/782], Loss: 0.1460\n",
            "Epoch [108/250], Step [600/782], Loss: 0.2583\n",
            "Epoch [108/250], Step [700/782], Loss: 0.2062\n",
            "Epoch [109/250], Step [0/782], Loss: 0.3700\n",
            "Epoch [109/250], Step [100/782], Loss: 0.1181\n",
            "Epoch [109/250], Step [200/782], Loss: 0.1446\n",
            "Epoch [109/250], Step [300/782], Loss: 0.2261\n",
            "Epoch [109/250], Step [400/782], Loss: 0.3119\n",
            "Epoch [109/250], Step [500/782], Loss: 0.1338\n",
            "Epoch [109/250], Step [600/782], Loss: 0.2611\n",
            "Epoch [109/250], Step [700/782], Loss: 0.3922\n",
            "Epoch [110/250], Step [0/782], Loss: 0.2023\n",
            "Epoch [110/250], Step [100/782], Loss: 0.2018\n",
            "Epoch [110/250], Step [200/782], Loss: 0.2233\n",
            "Epoch [110/250], Step [300/782], Loss: 0.4306\n",
            "Epoch [110/250], Step [400/782], Loss: 0.2342\n",
            "Epoch [110/250], Step [500/782], Loss: 0.3647\n",
            "Epoch [110/250], Step [600/782], Loss: 0.2971\n",
            "Epoch [110/250], Step [700/782], Loss: 0.1774\n",
            "Epoch [111/250], Step [0/782], Loss: 0.2405\n",
            "Epoch [111/250], Step [100/782], Loss: 0.2376\n",
            "Epoch [111/250], Step [200/782], Loss: 0.1949\n",
            "Epoch [111/250], Step [300/782], Loss: 0.3184\n",
            "Epoch [111/250], Step [400/782], Loss: 0.1843\n",
            "Epoch [111/250], Step [500/782], Loss: 0.1995\n",
            "Epoch [111/250], Step [600/782], Loss: 0.4633\n",
            "Epoch [111/250], Step [700/782], Loss: 0.1517\n",
            "Epoch [112/250], Step [0/782], Loss: 0.2131\n",
            "Epoch [112/250], Step [100/782], Loss: 0.3933\n",
            "Epoch [112/250], Step [200/782], Loss: 0.3746\n",
            "Epoch [112/250], Step [300/782], Loss: 0.2315\n",
            "Epoch [112/250], Step [400/782], Loss: 0.3162\n",
            "Epoch [112/250], Step [500/782], Loss: 0.1208\n",
            "Epoch [112/250], Step [600/782], Loss: 0.2306\n",
            "Epoch [112/250], Step [700/782], Loss: 0.2512\n",
            "Epoch [113/250], Step [0/782], Loss: 0.3170\n",
            "Epoch [113/250], Step [100/782], Loss: 0.1938\n",
            "Epoch [113/250], Step [200/782], Loss: 0.1248\n",
            "Epoch [113/250], Step [300/782], Loss: 0.4251\n",
            "Epoch [113/250], Step [400/782], Loss: 0.1417\n",
            "Epoch [113/250], Step [500/782], Loss: 0.2226\n",
            "Epoch [113/250], Step [600/782], Loss: 0.1831\n",
            "Epoch [113/250], Step [700/782], Loss: 0.1962\n",
            "Epoch [114/250], Step [0/782], Loss: 0.2385\n",
            "Epoch [114/250], Step [100/782], Loss: 0.1961\n",
            "Epoch [114/250], Step [200/782], Loss: 0.3392\n",
            "Epoch [114/250], Step [300/782], Loss: 0.2751\n",
            "Epoch [114/250], Step [400/782], Loss: 0.3008\n",
            "Epoch [114/250], Step [500/782], Loss: 0.1875\n",
            "Epoch [114/250], Step [600/782], Loss: 0.1937\n",
            "Epoch [114/250], Step [700/782], Loss: 0.4026\n",
            "Epoch [115/250], Step [0/782], Loss: 0.3455\n",
            "Epoch [115/250], Step [100/782], Loss: 0.2646\n",
            "Epoch [115/250], Step [200/782], Loss: 0.2799\n",
            "Epoch [115/250], Step [300/782], Loss: 0.2593\n",
            "Epoch [115/250], Step [400/782], Loss: 0.2091\n",
            "Epoch [115/250], Step [500/782], Loss: 0.2101\n",
            "Epoch [115/250], Step [600/782], Loss: 0.1431\n",
            "Epoch [115/250], Step [700/782], Loss: 0.1739\n",
            "Epoch [116/250], Step [0/782], Loss: 0.0804\n",
            "Epoch [116/250], Step [100/782], Loss: 0.1383\n",
            "Epoch [116/250], Step [200/782], Loss: 0.1498\n",
            "Epoch [116/250], Step [300/782], Loss: 0.3019\n",
            "Epoch [116/250], Step [400/782], Loss: 0.3640\n",
            "Epoch [116/250], Step [500/782], Loss: 0.1245\n",
            "Epoch [116/250], Step [600/782], Loss: 0.1870\n",
            "Epoch [116/250], Step [700/782], Loss: 0.2235\n",
            "Epoch [117/250], Step [0/782], Loss: 0.1929\n",
            "Epoch [117/250], Step [100/782], Loss: 0.1330\n",
            "Epoch [117/250], Step [200/782], Loss: 0.2707\n",
            "Epoch [117/250], Step [300/782], Loss: 0.2794\n",
            "Epoch [117/250], Step [400/782], Loss: 0.2844\n",
            "Epoch [117/250], Step [500/782], Loss: 0.1987\n",
            "Epoch [117/250], Step [600/782], Loss: 0.2184\n",
            "Epoch [117/250], Step [700/782], Loss: 0.1855\n",
            "Epoch [118/250], Step [0/782], Loss: 0.2000\n",
            "Epoch [118/250], Step [100/782], Loss: 0.1548\n",
            "Epoch [118/250], Step [200/782], Loss: 0.1875\n",
            "Epoch [118/250], Step [300/782], Loss: 0.1844\n",
            "Epoch [118/250], Step [400/782], Loss: 0.1699\n",
            "Epoch [118/250], Step [500/782], Loss: 0.2833\n",
            "Epoch [118/250], Step [600/782], Loss: 0.1209\n",
            "Epoch [118/250], Step [700/782], Loss: 0.2926\n",
            "Epoch [119/250], Step [0/782], Loss: 0.1110\n",
            "Epoch [119/250], Step [100/782], Loss: 0.1351\n",
            "Epoch [119/250], Step [200/782], Loss: 0.1747\n",
            "Epoch [119/250], Step [300/782], Loss: 0.1629\n",
            "Epoch [119/250], Step [400/782], Loss: 0.1150\n",
            "Epoch [119/250], Step [500/782], Loss: 0.1761\n",
            "Epoch [119/250], Step [600/782], Loss: 0.3377\n",
            "Epoch [119/250], Step [700/782], Loss: 0.2394\n",
            "Epoch [120/250], Step [0/782], Loss: 0.1508\n",
            "Epoch [120/250], Step [100/782], Loss: 0.3084\n",
            "Epoch [120/250], Step [200/782], Loss: 0.2397\n",
            "Epoch [120/250], Step [300/782], Loss: 0.1097\n",
            "Epoch [120/250], Step [400/782], Loss: 0.2908\n",
            "Epoch [120/250], Step [500/782], Loss: 0.2165\n",
            "Epoch [120/250], Step [600/782], Loss: 0.1118\n",
            "Epoch [120/250], Step [700/782], Loss: 0.1552\n",
            "Epoch [121/250], Step [0/782], Loss: 0.2033\n",
            "Epoch [121/250], Step [100/782], Loss: 0.1459\n",
            "Epoch [121/250], Step [200/782], Loss: 0.1522\n",
            "Epoch [121/250], Step [300/782], Loss: 0.1824\n",
            "Epoch [121/250], Step [400/782], Loss: 0.3633\n",
            "Epoch [121/250], Step [500/782], Loss: 0.1371\n",
            "Epoch [121/250], Step [600/782], Loss: 0.2374\n",
            "Epoch [121/250], Step [700/782], Loss: 0.2574\n",
            "Epoch [122/250], Step [0/782], Loss: 0.1394\n",
            "Epoch [122/250], Step [100/782], Loss: 0.2740\n",
            "Epoch [122/250], Step [200/782], Loss: 0.1760\n",
            "Epoch [122/250], Step [300/782], Loss: 0.1528\n",
            "Epoch [122/250], Step [400/782], Loss: 0.1801\n",
            "Epoch [122/250], Step [500/782], Loss: 0.1266\n",
            "Epoch [122/250], Step [600/782], Loss: 0.2791\n",
            "Epoch [122/250], Step [700/782], Loss: 0.1795\n",
            "Epoch [123/250], Step [0/782], Loss: 0.1609\n",
            "Epoch [123/250], Step [100/782], Loss: 0.1872\n",
            "Epoch [123/250], Step [200/782], Loss: 0.1840\n",
            "Epoch [123/250], Step [300/782], Loss: 0.1914\n",
            "Epoch [123/250], Step [400/782], Loss: 0.1185\n",
            "Epoch [123/250], Step [500/782], Loss: 0.2374\n",
            "Epoch [123/250], Step [600/782], Loss: 0.1400\n",
            "Epoch [123/250], Step [700/782], Loss: 0.4335\n",
            "Epoch [124/250], Step [0/782], Loss: 0.2713\n",
            "Epoch [124/250], Step [100/782], Loss: 0.2163\n",
            "Epoch [124/250], Step [200/782], Loss: 0.1251\n",
            "Epoch [124/250], Step [300/782], Loss: 0.0999\n",
            "Epoch [124/250], Step [400/782], Loss: 0.1567\n",
            "Epoch [124/250], Step [500/782], Loss: 0.2417\n",
            "Epoch [124/250], Step [600/782], Loss: 0.1552\n",
            "Epoch [124/250], Step [700/782], Loss: 0.1176\n",
            "Epoch [125/250], Step [0/782], Loss: 0.3470\n",
            "Epoch [125/250], Step [100/782], Loss: 0.1686\n",
            "Epoch [125/250], Step [200/782], Loss: 0.2334\n",
            "Epoch [125/250], Step [300/782], Loss: 0.2249\n",
            "Epoch [125/250], Step [400/782], Loss: 0.1886\n",
            "Epoch [125/250], Step [500/782], Loss: 0.1859\n",
            "Epoch [125/250], Step [600/782], Loss: 0.1579\n",
            "Epoch [125/250], Step [700/782], Loss: 0.0990\n",
            "Epoch [126/250], Step [0/782], Loss: 0.2182\n",
            "Epoch [126/250], Step [100/782], Loss: 0.1552\n",
            "Epoch [126/250], Step [200/782], Loss: 0.2081\n",
            "Epoch [126/250], Step [300/782], Loss: 0.1575\n",
            "Epoch [126/250], Step [400/782], Loss: 0.2222\n",
            "Epoch [126/250], Step [500/782], Loss: 0.0764\n",
            "Epoch [126/250], Step [600/782], Loss: 0.2461\n",
            "Epoch [126/250], Step [700/782], Loss: 0.1562\n",
            "Epoch [127/250], Step [0/782], Loss: 0.2368\n",
            "Epoch [127/250], Step [100/782], Loss: 0.2354\n",
            "Epoch [127/250], Step [200/782], Loss: 0.1322\n",
            "Epoch [127/250], Step [300/782], Loss: 0.1176\n",
            "Epoch [127/250], Step [400/782], Loss: 0.1707\n",
            "Epoch [127/250], Step [500/782], Loss: 0.1086\n",
            "Epoch [127/250], Step [600/782], Loss: 0.0656\n",
            "Epoch [127/250], Step [700/782], Loss: 0.1770\n",
            "Epoch [128/250], Step [0/782], Loss: 0.1228\n",
            "Epoch [128/250], Step [100/782], Loss: 0.1063\n",
            "Epoch [128/250], Step [200/782], Loss: 0.1581\n",
            "Epoch [128/250], Step [300/782], Loss: 0.2815\n",
            "Epoch [128/250], Step [400/782], Loss: 0.2005\n",
            "Epoch [128/250], Step [500/782], Loss: 0.1409\n",
            "Epoch [128/250], Step [600/782], Loss: 0.0879\n",
            "Epoch [128/250], Step [700/782], Loss: 0.0862\n",
            "Epoch [129/250], Step [0/782], Loss: 0.0410\n",
            "Epoch [129/250], Step [100/782], Loss: 0.1038\n",
            "Epoch [129/250], Step [200/782], Loss: 0.0868\n",
            "Epoch [129/250], Step [300/782], Loss: 0.1244\n",
            "Epoch [129/250], Step [400/782], Loss: 0.0963\n",
            "Epoch [129/250], Step [500/782], Loss: 0.1980\n",
            "Epoch [129/250], Step [600/782], Loss: 0.1988\n",
            "Epoch [129/250], Step [700/782], Loss: 0.3064\n",
            "Epoch [130/250], Step [0/782], Loss: 0.1404\n",
            "Epoch [130/250], Step [100/782], Loss: 0.2154\n",
            "Epoch [130/250], Step [200/782], Loss: 0.2080\n",
            "Epoch [130/250], Step [300/782], Loss: 0.1765\n",
            "Epoch [130/250], Step [400/782], Loss: 0.1908\n",
            "Epoch [130/250], Step [500/782], Loss: 0.0865\n",
            "Epoch [130/250], Step [600/782], Loss: 0.3235\n",
            "Epoch [130/250], Step [700/782], Loss: 0.1281\n",
            "Epoch [131/250], Step [0/782], Loss: 0.1147\n",
            "Epoch [131/250], Step [100/782], Loss: 0.2147\n",
            "Epoch [131/250], Step [200/782], Loss: 0.2197\n",
            "Epoch [131/250], Step [300/782], Loss: 0.0736\n",
            "Epoch [131/250], Step [400/782], Loss: 0.1825\n",
            "Epoch [131/250], Step [500/782], Loss: 0.1380\n",
            "Epoch [131/250], Step [600/782], Loss: 0.1630\n",
            "Epoch [131/250], Step [700/782], Loss: 0.4201\n",
            "Epoch [132/250], Step [0/782], Loss: 0.0867\n",
            "Epoch [132/250], Step [100/782], Loss: 0.1731\n",
            "Epoch [132/250], Step [200/782], Loss: 0.3325\n",
            "Epoch [132/250], Step [300/782], Loss: 0.2089\n",
            "Epoch [132/250], Step [400/782], Loss: 0.1528\n",
            "Epoch [132/250], Step [500/782], Loss: 0.1484\n",
            "Epoch [132/250], Step [600/782], Loss: 0.1428\n",
            "Epoch [132/250], Step [700/782], Loss: 0.3454\n",
            "Epoch [133/250], Step [0/782], Loss: 0.1992\n",
            "Epoch [133/250], Step [100/782], Loss: 0.1967\n",
            "Epoch [133/250], Step [200/782], Loss: 0.2351\n",
            "Epoch [133/250], Step [300/782], Loss: 0.2118\n",
            "Epoch [133/250], Step [400/782], Loss: 0.1604\n",
            "Epoch [133/250], Step [500/782], Loss: 0.2466\n",
            "Epoch [133/250], Step [600/782], Loss: 0.1379\n",
            "Epoch [133/250], Step [700/782], Loss: 0.1051\n",
            "Epoch [134/250], Step [0/782], Loss: 0.2287\n",
            "Epoch [134/250], Step [100/782], Loss: 0.1554\n",
            "Epoch [134/250], Step [200/782], Loss: 0.1756\n",
            "Epoch [134/250], Step [300/782], Loss: 0.1902\n",
            "Epoch [134/250], Step [400/782], Loss: 0.0579\n",
            "Epoch [134/250], Step [500/782], Loss: 0.1572\n",
            "Epoch [134/250], Step [600/782], Loss: 0.0703\n",
            "Epoch [134/250], Step [700/782], Loss: 0.1454\n",
            "Epoch [135/250], Step [0/782], Loss: 0.1212\n",
            "Epoch [135/250], Step [100/782], Loss: 0.3340\n",
            "Epoch [135/250], Step [200/782], Loss: 0.1226\n",
            "Epoch [135/250], Step [300/782], Loss: 0.2192\n",
            "Epoch [135/250], Step [400/782], Loss: 0.1876\n",
            "Epoch [135/250], Step [500/782], Loss: 0.1547\n",
            "Epoch [135/250], Step [600/782], Loss: 0.1439\n",
            "Epoch [135/250], Step [700/782], Loss: 0.0942\n",
            "Epoch [136/250], Step [0/782], Loss: 0.0938\n",
            "Epoch [136/250], Step [100/782], Loss: 0.3367\n",
            "Epoch [136/250], Step [200/782], Loss: 0.1385\n",
            "Epoch [136/250], Step [300/782], Loss: 0.1578\n",
            "Epoch [136/250], Step [400/782], Loss: 0.0980\n",
            "Epoch [136/250], Step [500/782], Loss: 0.1192\n",
            "Epoch [136/250], Step [600/782], Loss: 0.2529\n",
            "Epoch [136/250], Step [700/782], Loss: 0.1311\n",
            "Epoch [137/250], Step [0/782], Loss: 0.0554\n",
            "Epoch [137/250], Step [100/782], Loss: 0.1970\n",
            "Epoch [137/250], Step [200/782], Loss: 0.1913\n",
            "Epoch [137/250], Step [300/782], Loss: 0.1620\n",
            "Epoch [137/250], Step [400/782], Loss: 0.1886\n",
            "Epoch [137/250], Step [500/782], Loss: 0.2424\n",
            "Epoch [137/250], Step [600/782], Loss: 0.0574\n",
            "Epoch [137/250], Step [700/782], Loss: 0.1347\n",
            "Epoch [138/250], Step [0/782], Loss: 0.2764\n",
            "Epoch [138/250], Step [100/782], Loss: 0.2622\n",
            "Epoch [138/250], Step [200/782], Loss: 0.1391\n",
            "Epoch [138/250], Step [300/782], Loss: 0.0587\n",
            "Epoch [138/250], Step [400/782], Loss: 0.1831\n",
            "Epoch [138/250], Step [500/782], Loss: 0.3106\n",
            "Epoch [138/250], Step [600/782], Loss: 0.1399\n",
            "Epoch [138/250], Step [700/782], Loss: 0.0612\n",
            "Epoch [139/250], Step [0/782], Loss: 0.1118\n",
            "Epoch [139/250], Step [100/782], Loss: 0.0930\n",
            "Epoch [139/250], Step [200/782], Loss: 0.1905\n",
            "Epoch [139/250], Step [300/782], Loss: 0.1819\n",
            "Epoch [139/250], Step [400/782], Loss: 0.2408\n",
            "Epoch [139/250], Step [500/782], Loss: 0.1750\n",
            "Epoch [139/250], Step [600/782], Loss: 0.1100\n",
            "Epoch [139/250], Step [700/782], Loss: 0.3368\n",
            "Epoch [140/250], Step [0/782], Loss: 0.0743\n",
            "Epoch [140/250], Step [100/782], Loss: 0.2242\n",
            "Epoch [140/250], Step [200/782], Loss: 0.1648\n",
            "Epoch [140/250], Step [300/782], Loss: 0.2202\n",
            "Epoch [140/250], Step [400/782], Loss: 0.1047\n",
            "Epoch [140/250], Step [500/782], Loss: 0.3737\n",
            "Epoch [140/250], Step [600/782], Loss: 0.1915\n",
            "Epoch [140/250], Step [700/782], Loss: 0.1269\n",
            "Epoch [141/250], Step [0/782], Loss: 0.0966\n",
            "Epoch [141/250], Step [100/782], Loss: 0.1735\n",
            "Epoch [141/250], Step [200/782], Loss: 0.2033\n",
            "Epoch [141/250], Step [300/782], Loss: 0.1322\n",
            "Epoch [141/250], Step [400/782], Loss: 0.2066\n",
            "Epoch [141/250], Step [500/782], Loss: 0.0902\n",
            "Epoch [141/250], Step [600/782], Loss: 0.2230\n",
            "Epoch [141/250], Step [700/782], Loss: 0.1350\n",
            "Epoch [142/250], Step [0/782], Loss: 0.2417\n",
            "Epoch [142/250], Step [100/782], Loss: 0.2389\n",
            "Epoch [142/250], Step [200/782], Loss: 0.2146\n",
            "Epoch [142/250], Step [300/782], Loss: 0.1069\n",
            "Epoch [142/250], Step [400/782], Loss: 0.0629\n",
            "Epoch [142/250], Step [500/782], Loss: 0.1387\n",
            "Epoch [142/250], Step [600/782], Loss: 0.3104\n",
            "Epoch [142/250], Step [700/782], Loss: 0.1681\n",
            "Epoch [143/250], Step [0/782], Loss: 0.2661\n",
            "Epoch [143/250], Step [100/782], Loss: 0.2273\n",
            "Epoch [143/250], Step [200/782], Loss: 0.0604\n",
            "Epoch [143/250], Step [300/782], Loss: 0.1407\n",
            "Epoch [143/250], Step [400/782], Loss: 0.1365\n",
            "Epoch [143/250], Step [500/782], Loss: 0.3041\n",
            "Epoch [143/250], Step [600/782], Loss: 0.2349\n",
            "Epoch [143/250], Step [700/782], Loss: 0.1614\n",
            "Epoch [144/250], Step [0/782], Loss: 0.0961\n",
            "Epoch [144/250], Step [100/782], Loss: 0.1258\n",
            "Epoch [144/250], Step [200/782], Loss: 0.1885\n",
            "Epoch [144/250], Step [300/782], Loss: 0.1294\n",
            "Epoch [144/250], Step [400/782], Loss: 0.1376\n",
            "Epoch [144/250], Step [500/782], Loss: 0.0857\n",
            "Epoch [144/250], Step [600/782], Loss: 0.1484\n",
            "Epoch [144/250], Step [700/782], Loss: 0.1201\n",
            "Epoch [145/250], Step [0/782], Loss: 0.1381\n",
            "Epoch [145/250], Step [100/782], Loss: 0.1666\n",
            "Epoch [145/250], Step [200/782], Loss: 0.1419\n",
            "Epoch [145/250], Step [300/782], Loss: 0.0616\n",
            "Epoch [145/250], Step [400/782], Loss: 0.1520\n",
            "Epoch [145/250], Step [500/782], Loss: 0.0509\n",
            "Epoch [145/250], Step [600/782], Loss: 0.1232\n",
            "Epoch [145/250], Step [700/782], Loss: 0.0775\n",
            "Epoch [146/250], Step [0/782], Loss: 0.1391\n",
            "Epoch [146/250], Step [100/782], Loss: 0.1621\n",
            "Epoch [146/250], Step [200/782], Loss: 0.1469\n",
            "Epoch [146/250], Step [300/782], Loss: 0.1842\n",
            "Epoch [146/250], Step [400/782], Loss: 0.1849\n",
            "Epoch [146/250], Step [500/782], Loss: 0.0908\n",
            "Epoch [146/250], Step [600/782], Loss: 0.0955\n",
            "Epoch [146/250], Step [700/782], Loss: 0.1831\n",
            "Epoch [147/250], Step [0/782], Loss: 0.1381\n",
            "Epoch [147/250], Step [100/782], Loss: 0.0682\n",
            "Epoch [147/250], Step [200/782], Loss: 0.1049\n",
            "Epoch [147/250], Step [300/782], Loss: 0.0757\n",
            "Epoch [147/250], Step [400/782], Loss: 0.1847\n",
            "Epoch [147/250], Step [500/782], Loss: 0.0556\n",
            "Epoch [147/250], Step [600/782], Loss: 0.0834\n",
            "Epoch [147/250], Step [700/782], Loss: 0.2827\n",
            "Epoch [148/250], Step [0/782], Loss: 0.0668\n",
            "Epoch [148/250], Step [100/782], Loss: 0.2086\n",
            "Epoch [148/250], Step [200/782], Loss: 0.1335\n",
            "Epoch [148/250], Step [300/782], Loss: 0.1841\n",
            "Epoch [148/250], Step [400/782], Loss: 0.1062\n",
            "Epoch [148/250], Step [500/782], Loss: 0.1495\n",
            "Epoch [148/250], Step [600/782], Loss: 0.0844\n",
            "Epoch [148/250], Step [700/782], Loss: 0.1551\n",
            "Epoch [149/250], Step [0/782], Loss: 0.1025\n",
            "Epoch [149/250], Step [100/782], Loss: 0.0996\n",
            "Epoch [149/250], Step [200/782], Loss: 0.2093\n",
            "Epoch [149/250], Step [300/782], Loss: 0.0792\n",
            "Epoch [149/250], Step [400/782], Loss: 0.1065\n",
            "Epoch [149/250], Step [500/782], Loss: 0.1302\n",
            "Epoch [149/250], Step [600/782], Loss: 0.0966\n",
            "Epoch [149/250], Step [700/782], Loss: 0.0834\n",
            "Epoch [150/250], Step [0/782], Loss: 0.1730\n",
            "Epoch [150/250], Step [100/782], Loss: 0.1266\n",
            "Epoch [150/250], Step [200/782], Loss: 0.2069\n",
            "Epoch [150/250], Step [300/782], Loss: 0.1583\n",
            "Epoch [150/250], Step [400/782], Loss: 0.0714\n",
            "Epoch [150/250], Step [500/782], Loss: 0.1883\n",
            "Epoch [150/250], Step [600/782], Loss: 0.1428\n",
            "Epoch [150/250], Step [700/782], Loss: 0.1572\n",
            "Epoch [151/250], Step [0/782], Loss: 0.1048\n",
            "Epoch [151/250], Step [100/782], Loss: 0.1243\n",
            "Epoch [151/250], Step [200/782], Loss: 0.0753\n",
            "Epoch [151/250], Step [300/782], Loss: 0.1142\n",
            "Epoch [151/250], Step [400/782], Loss: 0.0610\n",
            "Epoch [151/250], Step [500/782], Loss: 0.0855\n",
            "Epoch [151/250], Step [600/782], Loss: 0.1959\n",
            "Epoch [151/250], Step [700/782], Loss: 0.1504\n",
            "Epoch [152/250], Step [0/782], Loss: 0.2142\n",
            "Epoch [152/250], Step [100/782], Loss: 0.0737\n",
            "Epoch [152/250], Step [200/782], Loss: 0.3261\n",
            "Epoch [152/250], Step [300/782], Loss: 0.1034\n",
            "Epoch [152/250], Step [400/782], Loss: 0.1796\n",
            "Epoch [152/250], Step [500/782], Loss: 0.2285\n",
            "Epoch [152/250], Step [600/782], Loss: 0.0802\n",
            "Epoch [152/250], Step [700/782], Loss: 0.2243\n",
            "Epoch [153/250], Step [0/782], Loss: 0.1877\n",
            "Epoch [153/250], Step [100/782], Loss: 0.1600\n",
            "Epoch [153/250], Step [200/782], Loss: 0.1590\n",
            "Epoch [153/250], Step [300/782], Loss: 0.1975\n",
            "Epoch [153/250], Step [400/782], Loss: 0.1360\n",
            "Epoch [153/250], Step [500/782], Loss: 0.1344\n",
            "Epoch [153/250], Step [600/782], Loss: 0.1104\n",
            "Epoch [153/250], Step [700/782], Loss: 0.1594\n",
            "Epoch [154/250], Step [0/782], Loss: 0.0812\n",
            "Epoch [154/250], Step [100/782], Loss: 0.0695\n",
            "Epoch [154/250], Step [200/782], Loss: 0.1369\n",
            "Epoch [154/250], Step [300/782], Loss: 0.1023\n",
            "Epoch [154/250], Step [400/782], Loss: 0.0831\n",
            "Epoch [154/250], Step [500/782], Loss: 0.1862\n",
            "Epoch [154/250], Step [600/782], Loss: 0.0856\n",
            "Epoch [154/250], Step [700/782], Loss: 0.1857\n",
            "Epoch [155/250], Step [0/782], Loss: 0.0471\n",
            "Epoch [155/250], Step [100/782], Loss: 0.0766\n",
            "Epoch [155/250], Step [200/782], Loss: 0.0999\n",
            "Epoch [155/250], Step [300/782], Loss: 0.0547\n",
            "Epoch [155/250], Step [400/782], Loss: 0.1062\n",
            "Epoch [155/250], Step [500/782], Loss: 0.1383\n",
            "Epoch [155/250], Step [600/782], Loss: 0.0327\n",
            "Epoch [155/250], Step [700/782], Loss: 0.1572\n",
            "Epoch [156/250], Step [0/782], Loss: 0.0660\n",
            "Epoch [156/250], Step [100/782], Loss: 0.1434\n",
            "Epoch [156/250], Step [200/782], Loss: 0.1595\n",
            "Epoch [156/250], Step [300/782], Loss: 0.1977\n",
            "Epoch [156/250], Step [400/782], Loss: 0.0361\n",
            "Epoch [156/250], Step [500/782], Loss: 0.1249\n",
            "Epoch [156/250], Step [600/782], Loss: 0.0914\n",
            "Epoch [156/250], Step [700/782], Loss: 0.0803\n",
            "Epoch [157/250], Step [0/782], Loss: 0.1626\n",
            "Epoch [157/250], Step [100/782], Loss: 0.0773\n",
            "Epoch [157/250], Step [200/782], Loss: 0.1510\n",
            "Epoch [157/250], Step [300/782], Loss: 0.0788\n",
            "Epoch [157/250], Step [400/782], Loss: 0.0381\n",
            "Epoch [157/250], Step [500/782], Loss: 0.1633\n",
            "Epoch [157/250], Step [600/782], Loss: 0.1197\n",
            "Epoch [157/250], Step [700/782], Loss: 0.1483\n",
            "Epoch [158/250], Step [0/782], Loss: 0.0704\n",
            "Epoch [158/250], Step [100/782], Loss: 0.1094\n",
            "Epoch [158/250], Step [200/782], Loss: 0.2524\n",
            "Epoch [158/250], Step [300/782], Loss: 0.1807\n",
            "Epoch [158/250], Step [400/782], Loss: 0.0872\n",
            "Epoch [158/250], Step [500/782], Loss: 0.0954\n",
            "Epoch [158/250], Step [600/782], Loss: 0.1462\n",
            "Epoch [158/250], Step [700/782], Loss: 0.0604\n",
            "Epoch [159/250], Step [0/782], Loss: 0.0777\n",
            "Epoch [159/250], Step [100/782], Loss: 0.1976\n",
            "Epoch [159/250], Step [200/782], Loss: 0.1688\n",
            "Epoch [159/250], Step [300/782], Loss: 0.1687\n",
            "Epoch [159/250], Step [400/782], Loss: 0.1805\n",
            "Epoch [159/250], Step [500/782], Loss: 0.1329\n",
            "Epoch [159/250], Step [600/782], Loss: 0.1404\n",
            "Epoch [159/250], Step [700/782], Loss: 0.1713\n",
            "Epoch [160/250], Step [0/782], Loss: 0.1200\n",
            "Epoch [160/250], Step [100/782], Loss: 0.0403\n",
            "Epoch [160/250], Step [200/782], Loss: 0.2339\n",
            "Epoch [160/250], Step [300/782], Loss: 0.0731\n",
            "Epoch [160/250], Step [400/782], Loss: 0.0925\n",
            "Epoch [160/250], Step [500/782], Loss: 0.0740\n",
            "Epoch [160/250], Step [600/782], Loss: 0.0704\n",
            "Epoch [160/250], Step [700/782], Loss: 0.0253\n",
            "Epoch [161/250], Step [0/782], Loss: 0.1305\n",
            "Epoch [161/250], Step [100/782], Loss: 0.0329\n",
            "Epoch [161/250], Step [200/782], Loss: 0.1162\n",
            "Epoch [161/250], Step [300/782], Loss: 0.0654\n",
            "Epoch [161/250], Step [400/782], Loss: 0.1088\n",
            "Epoch [161/250], Step [500/782], Loss: 0.1129\n",
            "Epoch [161/250], Step [600/782], Loss: 0.2212\n",
            "Epoch [161/250], Step [700/782], Loss: 0.0571\n",
            "Epoch [162/250], Step [0/782], Loss: 0.2063\n",
            "Epoch [162/250], Step [100/782], Loss: 0.0592\n",
            "Epoch [162/250], Step [200/782], Loss: 0.0401\n",
            "Epoch [162/250], Step [300/782], Loss: 0.1528\n",
            "Epoch [162/250], Step [400/782], Loss: 0.1413\n",
            "Epoch [162/250], Step [500/782], Loss: 0.0702\n",
            "Epoch [162/250], Step [600/782], Loss: 0.1041\n",
            "Epoch [162/250], Step [700/782], Loss: 0.1133\n",
            "Epoch [163/250], Step [0/782], Loss: 0.1016\n",
            "Epoch [163/250], Step [100/782], Loss: 0.2310\n",
            "Epoch [163/250], Step [200/782], Loss: 0.1126\n",
            "Epoch [163/250], Step [300/782], Loss: 0.1539\n",
            "Epoch [163/250], Step [400/782], Loss: 0.0590\n",
            "Epoch [163/250], Step [500/782], Loss: 0.1563\n",
            "Epoch [163/250], Step [600/782], Loss: 0.0985\n",
            "Epoch [163/250], Step [700/782], Loss: 0.2753\n",
            "Epoch [164/250], Step [0/782], Loss: 0.1617\n",
            "Epoch [164/250], Step [100/782], Loss: 0.2068\n",
            "Epoch [164/250], Step [200/782], Loss: 0.1253\n",
            "Epoch [164/250], Step [300/782], Loss: 0.0846\n",
            "Epoch [164/250], Step [400/782], Loss: 0.1112\n",
            "Epoch [164/250], Step [500/782], Loss: 0.1487\n",
            "Epoch [164/250], Step [600/782], Loss: 0.1591\n",
            "Epoch [164/250], Step [700/782], Loss: 0.0841\n",
            "Epoch [165/250], Step [0/782], Loss: 0.0979\n",
            "Epoch [165/250], Step [100/782], Loss: 0.2766\n",
            "Epoch [165/250], Step [200/782], Loss: 0.1340\n",
            "Epoch [165/250], Step [300/782], Loss: 0.1476\n",
            "Epoch [165/250], Step [400/782], Loss: 0.1697\n",
            "Epoch [165/250], Step [500/782], Loss: 0.1745\n",
            "Epoch [165/250], Step [600/782], Loss: 0.2356\n",
            "Epoch [165/250], Step [700/782], Loss: 0.0814\n",
            "Epoch [166/250], Step [0/782], Loss: 0.0876\n",
            "Epoch [166/250], Step [100/782], Loss: 0.1121\n",
            "Epoch [166/250], Step [200/782], Loss: 0.0485\n",
            "Epoch [166/250], Step [300/782], Loss: 0.1230\n",
            "Epoch [166/250], Step [400/782], Loss: 0.0865\n",
            "Epoch [166/250], Step [500/782], Loss: 0.1069\n",
            "Epoch [166/250], Step [600/782], Loss: 0.0738\n",
            "Epoch [166/250], Step [700/782], Loss: 0.1238\n",
            "Epoch [167/250], Step [0/782], Loss: 0.1303\n",
            "Epoch [167/250], Step [100/782], Loss: 0.1364\n",
            "Epoch [167/250], Step [200/782], Loss: 0.0684\n",
            "Epoch [167/250], Step [300/782], Loss: 0.0618\n",
            "Epoch [167/250], Step [400/782], Loss: 0.1018\n",
            "Epoch [167/250], Step [500/782], Loss: 0.1626\n",
            "Epoch [167/250], Step [600/782], Loss: 0.1600\n",
            "Epoch [167/250], Step [700/782], Loss: 0.0841\n",
            "Epoch [168/250], Step [0/782], Loss: 0.2123\n",
            "Epoch [168/250], Step [100/782], Loss: 0.0478\n",
            "Epoch [168/250], Step [200/782], Loss: 0.1762\n",
            "Epoch [168/250], Step [300/782], Loss: 0.1289\n",
            "Epoch [168/250], Step [400/782], Loss: 0.2909\n",
            "Epoch [168/250], Step [500/782], Loss: 0.1551\n",
            "Epoch [168/250], Step [600/782], Loss: 0.0866\n",
            "Epoch [168/250], Step [700/782], Loss: 0.1856\n",
            "Epoch [169/250], Step [0/782], Loss: 0.1484\n",
            "Epoch [169/250], Step [100/782], Loss: 0.1831\n",
            "Epoch [169/250], Step [200/782], Loss: 0.1086\n",
            "Epoch [169/250], Step [300/782], Loss: 0.2274\n",
            "Epoch [169/250], Step [400/782], Loss: 0.1291\n",
            "Epoch [169/250], Step [500/782], Loss: 0.2477\n",
            "Epoch [169/250], Step [600/782], Loss: 0.0644\n",
            "Epoch [169/250], Step [700/782], Loss: 0.1654\n",
            "Epoch [170/250], Step [0/782], Loss: 0.0709\n",
            "Epoch [170/250], Step [100/782], Loss: 0.1186\n",
            "Epoch [170/250], Step [200/782], Loss: 0.1507\n",
            "Epoch [170/250], Step [300/782], Loss: 0.0931\n",
            "Epoch [170/250], Step [400/782], Loss: 0.1618\n",
            "Epoch [170/250], Step [500/782], Loss: 0.1250\n",
            "Epoch [170/250], Step [600/782], Loss: 0.1785\n",
            "Epoch [170/250], Step [700/782], Loss: 0.1738\n",
            "Epoch [171/250], Step [0/782], Loss: 0.0617\n",
            "Epoch [171/250], Step [100/782], Loss: 0.1674\n",
            "Epoch [171/250], Step [200/782], Loss: 0.1336\n",
            "Epoch [171/250], Step [300/782], Loss: 0.1069\n",
            "Epoch [171/250], Step [400/782], Loss: 0.1183\n",
            "Epoch [171/250], Step [500/782], Loss: 0.1537\n",
            "Epoch [171/250], Step [600/782], Loss: 0.0564\n",
            "Epoch [171/250], Step [700/782], Loss: 0.1217\n",
            "Epoch [172/250], Step [0/782], Loss: 0.3073\n",
            "Epoch [172/250], Step [100/782], Loss: 0.1436\n",
            "Epoch [172/250], Step [200/782], Loss: 0.1052\n",
            "Epoch [172/250], Step [300/782], Loss: 0.0768\n",
            "Epoch [172/250], Step [400/782], Loss: 0.0182\n",
            "Epoch [172/250], Step [500/782], Loss: 0.3155\n",
            "Epoch [172/250], Step [600/782], Loss: 0.0398\n",
            "Epoch [172/250], Step [700/782], Loss: 0.1794\n",
            "Epoch [173/250], Step [0/782], Loss: 0.1374\n",
            "Epoch [173/250], Step [100/782], Loss: 0.0716\n",
            "Epoch [173/250], Step [200/782], Loss: 0.1292\n",
            "Epoch [173/250], Step [300/782], Loss: 0.2068\n",
            "Epoch [173/250], Step [400/782], Loss: 0.1911\n",
            "Epoch [173/250], Step [500/782], Loss: 0.0508\n",
            "Epoch [173/250], Step [600/782], Loss: 0.0979\n",
            "Epoch [173/250], Step [700/782], Loss: 0.0874\n",
            "Epoch [174/250], Step [0/782], Loss: 0.1194\n",
            "Epoch [174/250], Step [100/782], Loss: 0.2598\n",
            "Epoch [174/250], Step [200/782], Loss: 0.2513\n",
            "Epoch [174/250], Step [300/782], Loss: 0.1171\n",
            "Epoch [174/250], Step [400/782], Loss: 0.0775\n",
            "Epoch [174/250], Step [500/782], Loss: 0.0871\n",
            "Epoch [174/250], Step [600/782], Loss: 0.1411\n",
            "Epoch [174/250], Step [700/782], Loss: 0.1539\n",
            "Epoch [175/250], Step [0/782], Loss: 0.0891\n",
            "Epoch [175/250], Step [100/782], Loss: 0.0640\n",
            "Epoch [175/250], Step [200/782], Loss: 0.0614\n",
            "Epoch [175/250], Step [300/782], Loss: 0.1031\n",
            "Epoch [175/250], Step [400/782], Loss: 0.1430\n",
            "Epoch [175/250], Step [500/782], Loss: 0.0985\n",
            "Epoch [175/250], Step [600/782], Loss: 0.0419\n",
            "Epoch [175/250], Step [700/782], Loss: 0.0922\n",
            "Epoch [176/250], Step [0/782], Loss: 0.1486\n",
            "Epoch [176/250], Step [100/782], Loss: 0.0659\n",
            "Epoch [176/250], Step [200/782], Loss: 0.1100\n",
            "Epoch [176/250], Step [300/782], Loss: 0.0226\n",
            "Epoch [176/250], Step [400/782], Loss: 0.0487\n",
            "Epoch [176/250], Step [500/782], Loss: 0.1069\n",
            "Epoch [176/250], Step [600/782], Loss: 0.1546\n",
            "Epoch [176/250], Step [700/782], Loss: 0.1198\n",
            "Epoch [177/250], Step [0/782], Loss: 0.1612\n",
            "Epoch [177/250], Step [100/782], Loss: 0.1303\n",
            "Epoch [177/250], Step [200/782], Loss: 0.0723\n",
            "Epoch [177/250], Step [300/782], Loss: 0.0391\n",
            "Epoch [177/250], Step [400/782], Loss: 0.1006\n",
            "Epoch [177/250], Step [500/782], Loss: 0.0905\n",
            "Epoch [177/250], Step [600/782], Loss: 0.0681\n",
            "Epoch [177/250], Step [700/782], Loss: 0.1486\n",
            "Epoch [178/250], Step [0/782], Loss: 0.0849\n",
            "Epoch [178/250], Step [100/782], Loss: 0.0617\n",
            "Epoch [178/250], Step [200/782], Loss: 0.0333\n",
            "Epoch [178/250], Step [300/782], Loss: 0.0657\n",
            "Epoch [178/250], Step [400/782], Loss: 0.0446\n",
            "Epoch [178/250], Step [500/782], Loss: 0.2252\n",
            "Epoch [178/250], Step [600/782], Loss: 0.1672\n",
            "Epoch [178/250], Step [700/782], Loss: 0.1465\n",
            "Epoch [179/250], Step [0/782], Loss: 0.1324\n",
            "Epoch [179/250], Step [100/782], Loss: 0.1219\n",
            "Epoch [179/250], Step [200/782], Loss: 0.0924\n",
            "Epoch [179/250], Step [300/782], Loss: 0.0834\n",
            "Epoch [179/250], Step [400/782], Loss: 0.0813\n",
            "Epoch [179/250], Step [500/782], Loss: 0.0777\n",
            "Epoch [179/250], Step [600/782], Loss: 0.0740\n",
            "Epoch [179/250], Step [700/782], Loss: 0.0678\n",
            "Epoch [180/250], Step [0/782], Loss: 0.1230\n",
            "Epoch [180/250], Step [100/782], Loss: 0.1165\n",
            "Epoch [180/250], Step [200/782], Loss: 0.1376\n",
            "Epoch [180/250], Step [300/782], Loss: 0.0907\n",
            "Epoch [180/250], Step [400/782], Loss: 0.0244\n",
            "Epoch [180/250], Step [500/782], Loss: 0.1416\n",
            "Epoch [180/250], Step [600/782], Loss: 0.1326\n",
            "Epoch [180/250], Step [700/782], Loss: 0.0779\n",
            "Epoch [181/250], Step [0/782], Loss: 0.1145\n",
            "Epoch [181/250], Step [100/782], Loss: 0.0483\n",
            "Epoch [181/250], Step [200/782], Loss: 0.0754\n",
            "Epoch [181/250], Step [300/782], Loss: 0.1142\n",
            "Epoch [181/250], Step [400/782], Loss: 0.1544\n",
            "Epoch [181/250], Step [500/782], Loss: 0.1143\n",
            "Epoch [181/250], Step [600/782], Loss: 0.1302\n",
            "Epoch [181/250], Step [700/782], Loss: 0.0881\n",
            "Epoch [182/250], Step [0/782], Loss: 0.1770\n",
            "Epoch [182/250], Step [100/782], Loss: 0.0864\n",
            "Epoch [182/250], Step [200/782], Loss: 0.0155\n",
            "Epoch [182/250], Step [300/782], Loss: 0.0516\n",
            "Epoch [182/250], Step [400/782], Loss: 0.1634\n",
            "Epoch [182/250], Step [500/782], Loss: 0.0676\n",
            "Epoch [182/250], Step [600/782], Loss: 0.1630\n",
            "Epoch [182/250], Step [700/782], Loss: 0.0959\n",
            "Epoch [183/250], Step [0/782], Loss: 0.0559\n",
            "Epoch [183/250], Step [100/782], Loss: 0.0547\n",
            "Epoch [183/250], Step [200/782], Loss: 0.1266\n",
            "Epoch [183/250], Step [300/782], Loss: 0.0950\n",
            "Epoch [183/250], Step [400/782], Loss: 0.0521\n",
            "Epoch [183/250], Step [500/782], Loss: 0.0565\n",
            "Epoch [183/250], Step [600/782], Loss: 0.0474\n",
            "Epoch [183/250], Step [700/782], Loss: 0.1127\n",
            "Epoch [184/250], Step [0/782], Loss: 0.0866\n",
            "Epoch [184/250], Step [100/782], Loss: 0.0998\n",
            "Epoch [184/250], Step [200/782], Loss: 0.1395\n",
            "Epoch [184/250], Step [300/782], Loss: 0.1601\n",
            "Epoch [184/250], Step [400/782], Loss: 0.0532\n",
            "Epoch [184/250], Step [500/782], Loss: 0.0843\n",
            "Epoch [184/250], Step [600/782], Loss: 0.2095\n",
            "Epoch [184/250], Step [700/782], Loss: 0.0798\n",
            "Epoch [185/250], Step [0/782], Loss: 0.0764\n",
            "Epoch [185/250], Step [100/782], Loss: 0.1306\n",
            "Epoch [185/250], Step [200/782], Loss: 0.0372\n",
            "Epoch [185/250], Step [300/782], Loss: 0.1915\n",
            "Epoch [185/250], Step [400/782], Loss: 0.0816\n",
            "Epoch [185/250], Step [500/782], Loss: 0.0273\n",
            "Epoch [185/250], Step [600/782], Loss: 0.0269\n",
            "Epoch [185/250], Step [700/782], Loss: 0.0835\n",
            "Epoch [186/250], Step [0/782], Loss: 0.1305\n",
            "Epoch [186/250], Step [100/782], Loss: 0.1937\n",
            "Epoch [186/250], Step [200/782], Loss: 0.0940\n",
            "Epoch [186/250], Step [300/782], Loss: 0.2068\n",
            "Epoch [186/250], Step [400/782], Loss: 0.1334\n",
            "Epoch [186/250], Step [500/782], Loss: 0.0627\n",
            "Epoch [186/250], Step [600/782], Loss: 0.0696\n",
            "Epoch [186/250], Step [700/782], Loss: 0.2174\n",
            "Epoch [187/250], Step [0/782], Loss: 0.1063\n",
            "Epoch [187/250], Step [100/782], Loss: 0.0364\n",
            "Epoch [187/250], Step [200/782], Loss: 0.0267\n",
            "Epoch [187/250], Step [300/782], Loss: 0.1159\n",
            "Epoch [187/250], Step [400/782], Loss: 0.0502\n",
            "Epoch [187/250], Step [500/782], Loss: 0.1143\n",
            "Epoch [187/250], Step [600/782], Loss: 0.0221\n",
            "Epoch [187/250], Step [700/782], Loss: 0.0715\n",
            "Epoch [188/250], Step [0/782], Loss: 0.1406\n",
            "Epoch [188/250], Step [100/782], Loss: 0.0636\n",
            "Epoch [188/250], Step [200/782], Loss: 0.0923\n",
            "Epoch [188/250], Step [300/782], Loss: 0.1136\n",
            "Epoch [188/250], Step [400/782], Loss: 0.1005\n",
            "Epoch [188/250], Step [500/782], Loss: 0.0278\n",
            "Epoch [188/250], Step [600/782], Loss: 0.0558\n",
            "Epoch [188/250], Step [700/782], Loss: 0.0335\n",
            "Epoch [189/250], Step [0/782], Loss: 0.0576\n",
            "Epoch [189/250], Step [100/782], Loss: 0.2249\n",
            "Epoch [189/250], Step [200/782], Loss: 0.2233\n",
            "Epoch [189/250], Step [300/782], Loss: 0.0747\n",
            "Epoch [189/250], Step [400/782], Loss: 0.0206\n",
            "Epoch [189/250], Step [500/782], Loss: 0.0791\n",
            "Epoch [189/250], Step [600/782], Loss: 0.0858\n",
            "Epoch [189/250], Step [700/782], Loss: 0.0770\n",
            "Epoch [190/250], Step [0/782], Loss: 0.0762\n",
            "Epoch [190/250], Step [100/782], Loss: 0.1228\n",
            "Epoch [190/250], Step [200/782], Loss: 0.0487\n",
            "Epoch [190/250], Step [300/782], Loss: 0.0485\n",
            "Epoch [190/250], Step [400/782], Loss: 0.1170\n",
            "Epoch [190/250], Step [500/782], Loss: 0.1310\n",
            "Epoch [190/250], Step [600/782], Loss: 0.0800\n",
            "Epoch [190/250], Step [700/782], Loss: 0.1092\n",
            "Epoch [191/250], Step [0/782], Loss: 0.0727\n",
            "Epoch [191/250], Step [100/782], Loss: 0.1056\n",
            "Epoch [191/250], Step [200/782], Loss: 0.0334\n",
            "Epoch [191/250], Step [300/782], Loss: 0.0335\n",
            "Epoch [191/250], Step [400/782], Loss: 0.0184\n",
            "Epoch [191/250], Step [500/782], Loss: 0.1022\n",
            "Epoch [191/250], Step [600/782], Loss: 0.1335\n",
            "Epoch [191/250], Step [700/782], Loss: 0.1105\n",
            "Epoch [192/250], Step [0/782], Loss: 0.2192\n",
            "Epoch [192/250], Step [100/782], Loss: 0.0238\n",
            "Epoch [192/250], Step [200/782], Loss: 0.0708\n",
            "Epoch [192/250], Step [300/782], Loss: 0.0709\n",
            "Epoch [192/250], Step [400/782], Loss: 0.0635\n",
            "Epoch [192/250], Step [500/782], Loss: 0.0763\n",
            "Epoch [192/250], Step [600/782], Loss: 0.1216\n",
            "Epoch [192/250], Step [700/782], Loss: 0.0706\n",
            "Epoch [193/250], Step [0/782], Loss: 0.0171\n",
            "Epoch [193/250], Step [100/782], Loss: 0.0453\n",
            "Epoch [193/250], Step [200/782], Loss: 0.0591\n",
            "Epoch [193/250], Step [300/782], Loss: 0.1300\n",
            "Epoch [193/250], Step [400/782], Loss: 0.1364\n",
            "Epoch [193/250], Step [500/782], Loss: 0.1669\n",
            "Epoch [193/250], Step [600/782], Loss: 0.1140\n",
            "Epoch [193/250], Step [700/782], Loss: 0.0207\n",
            "Epoch [194/250], Step [0/782], Loss: 0.0714\n",
            "Epoch [194/250], Step [100/782], Loss: 0.0593\n",
            "Epoch [194/250], Step [200/782], Loss: 0.0732\n",
            "Epoch [194/250], Step [300/782], Loss: 0.0675\n",
            "Epoch [194/250], Step [400/782], Loss: 0.1480\n",
            "Epoch [194/250], Step [500/782], Loss: 0.0315\n",
            "Epoch [194/250], Step [600/782], Loss: 0.0504\n",
            "Epoch [194/250], Step [700/782], Loss: 0.2452\n",
            "Epoch [195/250], Step [0/782], Loss: 0.0415\n",
            "Epoch [195/250], Step [100/782], Loss: 0.0671\n",
            "Epoch [195/250], Step [200/782], Loss: 0.1652\n",
            "Epoch [195/250], Step [300/782], Loss: 0.0300\n",
            "Epoch [195/250], Step [400/782], Loss: 0.1921\n",
            "Epoch [195/250], Step [500/782], Loss: 0.1143\n",
            "Epoch [195/250], Step [600/782], Loss: 0.1222\n",
            "Epoch [195/250], Step [700/782], Loss: 0.1386\n",
            "Epoch [196/250], Step [0/782], Loss: 0.0859\n",
            "Epoch [196/250], Step [100/782], Loss: 0.1316\n",
            "Epoch [196/250], Step [200/782], Loss: 0.1471\n",
            "Epoch [196/250], Step [300/782], Loss: 0.0719\n",
            "Epoch [196/250], Step [400/782], Loss: 0.0669\n",
            "Epoch [196/250], Step [500/782], Loss: 0.1829\n",
            "Epoch [196/250], Step [600/782], Loss: 0.0524\n",
            "Epoch [196/250], Step [700/782], Loss: 0.2063\n",
            "Epoch [197/250], Step [0/782], Loss: 0.0814\n",
            "Epoch [197/250], Step [100/782], Loss: 0.0614\n",
            "Epoch [197/250], Step [200/782], Loss: 0.0828\n",
            "Epoch [197/250], Step [300/782], Loss: 0.0479\n",
            "Epoch [197/250], Step [400/782], Loss: 0.0382\n",
            "Epoch [197/250], Step [500/782], Loss: 0.0582\n",
            "Epoch [197/250], Step [600/782], Loss: 0.0853\n",
            "Epoch [197/250], Step [700/782], Loss: 0.0823\n",
            "Epoch [198/250], Step [0/782], Loss: 0.1193\n",
            "Epoch [198/250], Step [100/782], Loss: 0.0812\n",
            "Epoch [198/250], Step [200/782], Loss: 0.0297\n",
            "Epoch [198/250], Step [300/782], Loss: 0.0124\n",
            "Epoch [198/250], Step [400/782], Loss: 0.1301\n",
            "Epoch [198/250], Step [500/782], Loss: 0.0557\n",
            "Epoch [198/250], Step [600/782], Loss: 0.0661\n",
            "Epoch [198/250], Step [700/782], Loss: 0.0715\n",
            "Epoch [199/250], Step [0/782], Loss: 0.0662\n",
            "Epoch [199/250], Step [100/782], Loss: 0.0824\n",
            "Epoch [199/250], Step [200/782], Loss: 0.0526\n",
            "Epoch [199/250], Step [300/782], Loss: 0.1296\n",
            "Epoch [199/250], Step [400/782], Loss: 0.1813\n",
            "Epoch [199/250], Step [500/782], Loss: 0.0384\n",
            "Epoch [199/250], Step [600/782], Loss: 0.0466\n",
            "Epoch [199/250], Step [700/782], Loss: 0.0581\n",
            "Epoch [200/250], Step [0/782], Loss: 0.0408\n",
            "Epoch [200/250], Step [100/782], Loss: 0.0565\n",
            "Epoch [200/250], Step [200/782], Loss: 0.1111\n",
            "Epoch [200/250], Step [300/782], Loss: 0.0313\n",
            "Epoch [200/250], Step [400/782], Loss: 0.0675\n",
            "Epoch [200/250], Step [500/782], Loss: 0.0758\n",
            "Epoch [200/250], Step [600/782], Loss: 0.1367\n",
            "Epoch [200/250], Step [700/782], Loss: 0.1767\n",
            "Epoch [201/250], Step [0/782], Loss: 0.0647\n",
            "Epoch [201/250], Step [100/782], Loss: 0.0967\n",
            "Epoch [201/250], Step [200/782], Loss: 0.1831\n",
            "Epoch [201/250], Step [300/782], Loss: 0.1404\n",
            "Epoch [201/250], Step [400/782], Loss: 0.0867\n",
            "Epoch [201/250], Step [500/782], Loss: 0.0874\n",
            "Epoch [201/250], Step [600/782], Loss: 0.0519\n",
            "Epoch [201/250], Step [700/782], Loss: 0.1638\n",
            "Epoch [202/250], Step [0/782], Loss: 0.0155\n",
            "Epoch [202/250], Step [100/782], Loss: 0.0639\n",
            "Epoch [202/250], Step [200/782], Loss: 0.2985\n",
            "Epoch [202/250], Step [300/782], Loss: 0.0628\n",
            "Epoch [202/250], Step [400/782], Loss: 0.0845\n",
            "Epoch [202/250], Step [500/782], Loss: 0.0539\n",
            "Epoch [202/250], Step [600/782], Loss: 0.0408\n",
            "Epoch [202/250], Step [700/782], Loss: 0.0573\n",
            "Epoch [203/250], Step [0/782], Loss: 0.1193\n",
            "Epoch [203/250], Step [100/782], Loss: 0.1226\n",
            "Epoch [203/250], Step [200/782], Loss: 0.0883\n",
            "Epoch [203/250], Step [300/782], Loss: 0.0393\n",
            "Epoch [203/250], Step [400/782], Loss: 0.1060\n",
            "Epoch [203/250], Step [500/782], Loss: 0.0693\n",
            "Epoch [203/250], Step [600/782], Loss: 0.0742\n",
            "Epoch [203/250], Step [700/782], Loss: 0.0786\n",
            "Epoch [204/250], Step [0/782], Loss: 0.0645\n",
            "Epoch [204/250], Step [100/782], Loss: 0.1049\n",
            "Epoch [204/250], Step [200/782], Loss: 0.0484\n",
            "Epoch [204/250], Step [300/782], Loss: 0.1246\n",
            "Epoch [204/250], Step [400/782], Loss: 0.0309\n",
            "Epoch [204/250], Step [500/782], Loss: 0.0469\n",
            "Epoch [204/250], Step [600/782], Loss: 0.0789\n",
            "Epoch [204/250], Step [700/782], Loss: 0.0341\n",
            "Epoch [205/250], Step [0/782], Loss: 0.0812\n",
            "Epoch [205/250], Step [100/782], Loss: 0.0629\n",
            "Epoch [205/250], Step [200/782], Loss: 0.0631\n",
            "Epoch [205/250], Step [300/782], Loss: 0.0792\n",
            "Epoch [205/250], Step [400/782], Loss: 0.1138\n",
            "Epoch [205/250], Step [500/782], Loss: 0.0882\n",
            "Epoch [205/250], Step [600/782], Loss: 0.0572\n",
            "Epoch [205/250], Step [700/782], Loss: 0.1685\n",
            "Epoch [206/250], Step [0/782], Loss: 0.1070\n",
            "Epoch [206/250], Step [100/782], Loss: 0.0538\n",
            "Epoch [206/250], Step [200/782], Loss: 0.1076\n",
            "Epoch [206/250], Step [300/782], Loss: 0.0996\n",
            "Epoch [206/250], Step [400/782], Loss: 0.1490\n",
            "Epoch [206/250], Step [500/782], Loss: 0.0780\n",
            "Epoch [206/250], Step [600/782], Loss: 0.1343\n",
            "Epoch [206/250], Step [700/782], Loss: 0.0988\n",
            "Epoch [207/250], Step [0/782], Loss: 0.1770\n",
            "Epoch [207/250], Step [100/782], Loss: 0.2332\n",
            "Epoch [207/250], Step [200/782], Loss: 0.1110\n",
            "Epoch [207/250], Step [300/782], Loss: 0.1156\n",
            "Epoch [207/250], Step [400/782], Loss: 0.0452\n",
            "Epoch [207/250], Step [500/782], Loss: 0.1183\n",
            "Epoch [207/250], Step [600/782], Loss: 0.0139\n",
            "Epoch [207/250], Step [700/782], Loss: 0.0457\n",
            "Epoch [208/250], Step [0/782], Loss: 0.0616\n",
            "Epoch [208/250], Step [100/782], Loss: 0.0644\n",
            "Epoch [208/250], Step [200/782], Loss: 0.0102\n",
            "Epoch [208/250], Step [300/782], Loss: 0.1472\n",
            "Epoch [208/250], Step [400/782], Loss: 0.0860\n",
            "Epoch [208/250], Step [500/782], Loss: 0.1313\n",
            "Epoch [208/250], Step [600/782], Loss: 0.0734\n",
            "Epoch [208/250], Step [700/782], Loss: 0.1202\n",
            "Epoch [209/250], Step [0/782], Loss: 0.0615\n",
            "Epoch [209/250], Step [100/782], Loss: 0.0342\n",
            "Epoch [209/250], Step [200/782], Loss: 0.0540\n",
            "Epoch [209/250], Step [300/782], Loss: 0.0600\n",
            "Epoch [209/250], Step [400/782], Loss: 0.0218\n",
            "Epoch [209/250], Step [500/782], Loss: 0.1011\n",
            "Epoch [209/250], Step [600/782], Loss: 0.0189\n",
            "Epoch [209/250], Step [700/782], Loss: 0.1383\n",
            "Epoch [210/250], Step [0/782], Loss: 0.1077\n",
            "Epoch [210/250], Step [100/782], Loss: 0.0513\n",
            "Epoch [210/250], Step [200/782], Loss: 0.0825\n",
            "Epoch [210/250], Step [300/782], Loss: 0.0812\n",
            "Epoch [210/250], Step [400/782], Loss: 0.0212\n",
            "Epoch [210/250], Step [500/782], Loss: 0.0141\n",
            "Epoch [210/250], Step [600/782], Loss: 0.0529\n",
            "Epoch [210/250], Step [700/782], Loss: 0.0103\n",
            "Epoch [211/250], Step [0/782], Loss: 0.0848\n",
            "Epoch [211/250], Step [100/782], Loss: 0.0487\n",
            "Epoch [211/250], Step [200/782], Loss: 0.0243\n",
            "Epoch [211/250], Step [300/782], Loss: 0.0135\n",
            "Epoch [211/250], Step [400/782], Loss: 0.1180\n",
            "Epoch [211/250], Step [500/782], Loss: 0.0442\n",
            "Epoch [211/250], Step [600/782], Loss: 0.0748\n",
            "Epoch [211/250], Step [700/782], Loss: 0.0862\n",
            "Epoch [212/250], Step [0/782], Loss: 0.0292\n",
            "Epoch [212/250], Step [100/782], Loss: 0.0357\n",
            "Epoch [212/250], Step [200/782], Loss: 0.0571\n",
            "Epoch [212/250], Step [300/782], Loss: 0.2248\n",
            "Epoch [212/250], Step [400/782], Loss: 0.0739\n",
            "Epoch [212/250], Step [500/782], Loss: 0.1051\n",
            "Epoch [212/250], Step [600/782], Loss: 0.1600\n",
            "Epoch [212/250], Step [700/782], Loss: 0.1141\n",
            "Epoch [213/250], Step [0/782], Loss: 0.0891\n",
            "Epoch [213/250], Step [100/782], Loss: 0.0764\n",
            "Epoch [213/250], Step [200/782], Loss: 0.1433\n",
            "Epoch [213/250], Step [300/782], Loss: 0.1071\n",
            "Epoch [213/250], Step [400/782], Loss: 0.0604\n",
            "Epoch [213/250], Step [500/782], Loss: 0.1208\n",
            "Epoch [213/250], Step [600/782], Loss: 0.0959\n",
            "Epoch [213/250], Step [700/782], Loss: 0.1093\n",
            "Epoch [214/250], Step [0/782], Loss: 0.0552\n",
            "Epoch [214/250], Step [100/782], Loss: 0.0455\n",
            "Epoch [214/250], Step [200/782], Loss: 0.0380\n",
            "Epoch [214/250], Step [300/782], Loss: 0.0539\n",
            "Epoch [214/250], Step [400/782], Loss: 0.0446\n",
            "Epoch [214/250], Step [500/782], Loss: 0.0462\n",
            "Epoch [214/250], Step [600/782], Loss: 0.0342\n",
            "Epoch [214/250], Step [700/782], Loss: 0.0320\n",
            "Epoch [215/250], Step [0/782], Loss: 0.1830\n",
            "Epoch [215/250], Step [100/782], Loss: 0.0279\n",
            "Epoch [215/250], Step [200/782], Loss: 0.2342\n",
            "Epoch [215/250], Step [300/782], Loss: 0.1635\n",
            "Epoch [215/250], Step [400/782], Loss: 0.0747\n",
            "Epoch [215/250], Step [500/782], Loss: 0.0958\n",
            "Epoch [215/250], Step [600/782], Loss: 0.0227\n",
            "Epoch [215/250], Step [700/782], Loss: 0.0789\n",
            "Epoch [216/250], Step [0/782], Loss: 0.0884\n",
            "Epoch [216/250], Step [100/782], Loss: 0.0937\n",
            "Epoch [216/250], Step [200/782], Loss: 0.0312\n",
            "Epoch [216/250], Step [300/782], Loss: 0.1030\n",
            "Epoch [216/250], Step [400/782], Loss: 0.1880\n",
            "Epoch [216/250], Step [500/782], Loss: 0.0906\n",
            "Epoch [216/250], Step [600/782], Loss: 0.1701\n",
            "Epoch [216/250], Step [700/782], Loss: 0.0559\n",
            "Epoch [217/250], Step [0/782], Loss: 0.0406\n",
            "Epoch [217/250], Step [100/782], Loss: 0.0016\n",
            "Epoch [217/250], Step [200/782], Loss: 0.0834\n",
            "Epoch [217/250], Step [300/782], Loss: 0.0385\n",
            "Epoch [217/250], Step [400/782], Loss: 0.0821\n",
            "Epoch [217/250], Step [500/782], Loss: 0.0861\n",
            "Epoch [217/250], Step [600/782], Loss: 0.0876\n",
            "Epoch [217/250], Step [700/782], Loss: 0.0896\n",
            "Epoch [218/250], Step [0/782], Loss: 0.0336\n",
            "Epoch [218/250], Step [100/782], Loss: 0.0451\n",
            "Epoch [218/250], Step [200/782], Loss: 0.1866\n",
            "Epoch [218/250], Step [300/782], Loss: 0.1120\n",
            "Epoch [218/250], Step [400/782], Loss: 0.0536\n",
            "Epoch [218/250], Step [500/782], Loss: 0.1529\n",
            "Epoch [218/250], Step [600/782], Loss: 0.3132\n",
            "Epoch [218/250], Step [700/782], Loss: 0.0535\n",
            "Epoch [219/250], Step [0/782], Loss: 0.1707\n",
            "Epoch [219/250], Step [100/782], Loss: 0.0349\n",
            "Epoch [219/250], Step [200/782], Loss: 0.0363\n",
            "Epoch [219/250], Step [300/782], Loss: 0.0247\n",
            "Epoch [219/250], Step [400/782], Loss: 0.1213\n",
            "Epoch [219/250], Step [500/782], Loss: 0.1048\n",
            "Epoch [219/250], Step [600/782], Loss: 0.0162\n",
            "Epoch [219/250], Step [700/782], Loss: 0.1423\n",
            "Epoch [220/250], Step [0/782], Loss: 0.1189\n",
            "Epoch [220/250], Step [100/782], Loss: 0.0794\n",
            "Epoch [220/250], Step [200/782], Loss: 0.0297\n",
            "Epoch [220/250], Step [300/782], Loss: 0.0539\n",
            "Epoch [220/250], Step [400/782], Loss: 0.1713\n",
            "Epoch [220/250], Step [500/782], Loss: 0.0917\n",
            "Epoch [220/250], Step [600/782], Loss: 0.0412\n",
            "Epoch [220/250], Step [700/782], Loss: 0.0077\n",
            "Epoch [221/250], Step [0/782], Loss: 0.0366\n",
            "Epoch [221/250], Step [100/782], Loss: 0.0786\n",
            "Epoch [221/250], Step [200/782], Loss: 0.1042\n",
            "Epoch [221/250], Step [300/782], Loss: 0.0537\n",
            "Epoch [221/250], Step [400/782], Loss: 0.1481\n",
            "Epoch [221/250], Step [500/782], Loss: 0.1481\n",
            "Epoch [221/250], Step [600/782], Loss: 0.0329\n",
            "Epoch [221/250], Step [700/782], Loss: 0.0558\n",
            "Epoch [222/250], Step [0/782], Loss: 0.1213\n",
            "Epoch [222/250], Step [100/782], Loss: 0.0655\n",
            "Epoch [222/250], Step [200/782], Loss: 0.0452\n",
            "Epoch [222/250], Step [300/782], Loss: 0.0602\n",
            "Epoch [222/250], Step [400/782], Loss: 0.0110\n",
            "Epoch [222/250], Step [500/782], Loss: 0.0223\n",
            "Epoch [222/250], Step [600/782], Loss: 0.0076\n",
            "Epoch [222/250], Step [700/782], Loss: 0.0480\n",
            "Epoch [223/250], Step [0/782], Loss: 0.0565\n",
            "Epoch [223/250], Step [100/782], Loss: 0.0787\n",
            "Epoch [223/250], Step [200/782], Loss: 0.1874\n",
            "Epoch [223/250], Step [300/782], Loss: 0.0277\n",
            "Epoch [223/250], Step [400/782], Loss: 0.0603\n",
            "Epoch [223/250], Step [500/782], Loss: 0.0378\n",
            "Epoch [223/250], Step [600/782], Loss: 0.0512\n",
            "Epoch [223/250], Step [700/782], Loss: 0.1275\n",
            "Epoch [224/250], Step [0/782], Loss: 0.0489\n",
            "Epoch [224/250], Step [100/782], Loss: 0.0102\n",
            "Epoch [224/250], Step [200/782], Loss: 0.0667\n",
            "Epoch [224/250], Step [300/782], Loss: 0.0662\n",
            "Epoch [224/250], Step [400/782], Loss: 0.1285\n",
            "Epoch [224/250], Step [500/782], Loss: 0.1208\n",
            "Epoch [224/250], Step [600/782], Loss: 0.0600\n",
            "Epoch [224/250], Step [700/782], Loss: 0.0790\n",
            "Epoch [225/250], Step [0/782], Loss: 0.0655\n",
            "Epoch [225/250], Step [100/782], Loss: 0.1096\n",
            "Epoch [225/250], Step [200/782], Loss: 0.0688\n",
            "Epoch [225/250], Step [300/782], Loss: 0.0194\n",
            "Epoch [225/250], Step [400/782], Loss: 0.0251\n",
            "Epoch [225/250], Step [500/782], Loss: 0.1746\n",
            "Epoch [225/250], Step [600/782], Loss: 0.1037\n",
            "Epoch [225/250], Step [700/782], Loss: 0.0709\n",
            "Epoch [226/250], Step [0/782], Loss: 0.0556\n",
            "Epoch [226/250], Step [100/782], Loss: 0.1265\n",
            "Epoch [226/250], Step [200/782], Loss: 0.0452\n",
            "Epoch [226/250], Step [300/782], Loss: 0.2169\n",
            "Epoch [226/250], Step [400/782], Loss: 0.1379\n",
            "Epoch [226/250], Step [500/782], Loss: 0.0570\n",
            "Epoch [226/250], Step [600/782], Loss: 0.0467\n",
            "Epoch [226/250], Step [700/782], Loss: 0.0405\n",
            "Epoch [227/250], Step [0/782], Loss: 0.0293\n",
            "Epoch [227/250], Step [100/782], Loss: 0.0640\n",
            "Epoch [227/250], Step [200/782], Loss: 0.0901\n",
            "Epoch [227/250], Step [300/782], Loss: 0.1978\n",
            "Epoch [227/250], Step [400/782], Loss: 0.0683\n",
            "Epoch [227/250], Step [500/782], Loss: 0.0740\n",
            "Epoch [227/250], Step [600/782], Loss: 0.0928\n",
            "Epoch [227/250], Step [700/782], Loss: 0.0820\n",
            "Epoch [228/250], Step [0/782], Loss: 0.0263\n",
            "Epoch [228/250], Step [100/782], Loss: 0.0630\n",
            "Epoch [228/250], Step [200/782], Loss: 0.1701\n",
            "Epoch [228/250], Step [300/782], Loss: 0.0243\n",
            "Epoch [228/250], Step [400/782], Loss: 0.0712\n",
            "Epoch [228/250], Step [500/782], Loss: 0.0457\n",
            "Epoch [228/250], Step [600/782], Loss: 0.0231\n",
            "Epoch [228/250], Step [700/782], Loss: 0.0921\n",
            "Epoch [229/250], Step [0/782], Loss: 0.0490\n",
            "Epoch [229/250], Step [100/782], Loss: 0.0592\n",
            "Epoch [229/250], Step [200/782], Loss: 0.0372\n",
            "Epoch [229/250], Step [300/782], Loss: 0.0366\n",
            "Epoch [229/250], Step [400/782], Loss: 0.1236\n",
            "Epoch [229/250], Step [500/782], Loss: 0.1036\n",
            "Epoch [229/250], Step [600/782], Loss: 0.1470\n",
            "Epoch [229/250], Step [700/782], Loss: 0.0812\n",
            "Epoch [230/250], Step [0/782], Loss: 0.0209\n",
            "Epoch [230/250], Step [100/782], Loss: 0.0565\n",
            "Epoch [230/250], Step [200/782], Loss: 0.0372\n",
            "Epoch [230/250], Step [300/782], Loss: 0.0690\n",
            "Epoch [230/250], Step [400/782], Loss: 0.2122\n",
            "Epoch [230/250], Step [500/782], Loss: 0.0226\n",
            "Epoch [230/250], Step [600/782], Loss: 0.0147\n",
            "Epoch [230/250], Step [700/782], Loss: 0.0663\n",
            "Epoch [231/250], Step [0/782], Loss: 0.1283\n",
            "Epoch [231/250], Step [100/782], Loss: 0.0191\n",
            "Epoch [231/250], Step [200/782], Loss: 0.0473\n",
            "Epoch [231/250], Step [300/782], Loss: 0.1010\n",
            "Epoch [231/250], Step [400/782], Loss: 0.0208\n",
            "Epoch [231/250], Step [500/782], Loss: 0.0552\n",
            "Epoch [231/250], Step [600/782], Loss: 0.0717\n",
            "Epoch [231/250], Step [700/782], Loss: 0.0412\n",
            "Epoch [232/250], Step [0/782], Loss: 0.0952\n",
            "Epoch [232/250], Step [100/782], Loss: 0.1167\n",
            "Epoch [232/250], Step [200/782], Loss: 0.0344\n",
            "Epoch [232/250], Step [300/782], Loss: 0.0440\n",
            "Epoch [232/250], Step [400/782], Loss: 0.1435\n",
            "Epoch [232/250], Step [500/782], Loss: 0.0480\n",
            "Epoch [232/250], Step [600/782], Loss: 0.0251\n",
            "Epoch [232/250], Step [700/782], Loss: 0.2371\n",
            "Epoch [233/250], Step [0/782], Loss: 0.0455\n",
            "Epoch [233/250], Step [100/782], Loss: 0.0380\n",
            "Epoch [233/250], Step [200/782], Loss: 0.0590\n",
            "Epoch [233/250], Step [300/782], Loss: 0.0432\n",
            "Epoch [233/250], Step [400/782], Loss: 0.0520\n",
            "Epoch [233/250], Step [500/782], Loss: 0.0488\n",
            "Epoch [233/250], Step [600/782], Loss: 0.0367\n",
            "Epoch [233/250], Step [700/782], Loss: 0.0536\n",
            "Epoch [234/250], Step [0/782], Loss: 0.0381\n",
            "Epoch [234/250], Step [100/782], Loss: 0.1326\n",
            "Epoch [234/250], Step [200/782], Loss: 0.0629\n",
            "Epoch [234/250], Step [300/782], Loss: 0.0958\n",
            "Epoch [234/250], Step [400/782], Loss: 0.0725\n",
            "Epoch [234/250], Step [500/782], Loss: 0.0640\n",
            "Epoch [234/250], Step [600/782], Loss: 0.1558\n",
            "Epoch [234/250], Step [700/782], Loss: 0.1821\n",
            "Epoch [235/250], Step [0/782], Loss: 0.0413\n",
            "Epoch [235/250], Step [100/782], Loss: 0.0165\n",
            "Epoch [235/250], Step [200/782], Loss: 0.0241\n",
            "Epoch [235/250], Step [300/782], Loss: 0.1058\n",
            "Epoch [235/250], Step [400/782], Loss: 0.0477\n",
            "Epoch [235/250], Step [500/782], Loss: 0.0426\n",
            "Epoch [235/250], Step [600/782], Loss: 0.1265\n",
            "Epoch [235/250], Step [700/782], Loss: 0.1036\n",
            "Epoch [236/250], Step [0/782], Loss: 0.0160\n",
            "Epoch [236/250], Step [100/782], Loss: 0.0546\n",
            "Epoch [236/250], Step [200/782], Loss: 0.0676\n",
            "Epoch [236/250], Step [300/782], Loss: 0.0290\n",
            "Epoch [236/250], Step [400/782], Loss: 0.0647\n",
            "Epoch [236/250], Step [500/782], Loss: 0.0786\n",
            "Epoch [236/250], Step [600/782], Loss: 0.0281\n",
            "Epoch [236/250], Step [700/782], Loss: 0.0423\n",
            "Epoch [237/250], Step [0/782], Loss: 0.0213\n",
            "Epoch [237/250], Step [100/782], Loss: 0.0889\n",
            "Epoch [237/250], Step [200/782], Loss: 0.0136\n",
            "Epoch [237/250], Step [300/782], Loss: 0.0676\n",
            "Epoch [237/250], Step [400/782], Loss: 0.0888\n",
            "Epoch [237/250], Step [500/782], Loss: 0.1864\n",
            "Epoch [237/250], Step [600/782], Loss: 0.0810\n",
            "Epoch [237/250], Step [700/782], Loss: 0.0491\n",
            "Epoch [238/250], Step [0/782], Loss: 0.0550\n",
            "Epoch [238/250], Step [100/782], Loss: 0.0455\n",
            "Epoch [238/250], Step [200/782], Loss: 0.0534\n",
            "Epoch [238/250], Step [300/782], Loss: 0.1632\n",
            "Epoch [238/250], Step [400/782], Loss: 0.1236\n",
            "Epoch [238/250], Step [500/782], Loss: 0.0472\n",
            "Epoch [238/250], Step [600/782], Loss: 0.0269\n",
            "Epoch [238/250], Step [700/782], Loss: 0.2398\n",
            "Epoch [239/250], Step [0/782], Loss: 0.0189\n",
            "Epoch [239/250], Step [100/782], Loss: 0.0321\n",
            "Epoch [239/250], Step [200/782], Loss: 0.0526\n",
            "Epoch [239/250], Step [300/782], Loss: 0.0517\n",
            "Epoch [239/250], Step [400/782], Loss: 0.0203\n",
            "Epoch [239/250], Step [500/782], Loss: 0.0728\n",
            "Epoch [239/250], Step [600/782], Loss: 0.1496\n",
            "Epoch [239/250], Step [700/782], Loss: 0.0992\n",
            "Epoch [240/250], Step [0/782], Loss: 0.0912\n",
            "Epoch [240/250], Step [100/782], Loss: 0.0435\n",
            "Epoch [240/250], Step [200/782], Loss: 0.0487\n",
            "Epoch [240/250], Step [300/782], Loss: 0.0373\n",
            "Epoch [240/250], Step [400/782], Loss: 0.0929\n",
            "Epoch [240/250], Step [500/782], Loss: 0.0219\n",
            "Epoch [240/250], Step [600/782], Loss: 0.0964\n",
            "Epoch [240/250], Step [700/782], Loss: 0.0465\n",
            "Epoch [241/250], Step [0/782], Loss: 0.0170\n",
            "Epoch [241/250], Step [100/782], Loss: 0.0463\n",
            "Epoch [241/250], Step [200/782], Loss: 0.1776\n",
            "Epoch [241/250], Step [300/782], Loss: 0.1531\n",
            "Epoch [241/250], Step [400/782], Loss: 0.0629\n",
            "Epoch [241/250], Step [500/782], Loss: 0.1417\n",
            "Epoch [241/250], Step [600/782], Loss: 0.0612\n",
            "Epoch [241/250], Step [700/782], Loss: 0.0504\n",
            "Epoch [242/250], Step [0/782], Loss: 0.2028\n",
            "Epoch [242/250], Step [100/782], Loss: 0.1356\n",
            "Epoch [242/250], Step [200/782], Loss: 0.0514\n",
            "Epoch [242/250], Step [300/782], Loss: 0.0081\n",
            "Epoch [242/250], Step [400/782], Loss: 0.0665\n",
            "Epoch [242/250], Step [500/782], Loss: 0.1272\n",
            "Epoch [242/250], Step [600/782], Loss: 0.0622\n",
            "Epoch [242/250], Step [700/782], Loss: 0.0511\n",
            "Epoch [243/250], Step [0/782], Loss: 0.0207\n",
            "Epoch [243/250], Step [100/782], Loss: 0.1026\n",
            "Epoch [243/250], Step [200/782], Loss: 0.0549\n",
            "Epoch [243/250], Step [300/782], Loss: 0.1096\n",
            "Epoch [243/250], Step [400/782], Loss: 0.0351\n",
            "Epoch [243/250], Step [500/782], Loss: 0.1596\n",
            "Epoch [243/250], Step [600/782], Loss: 0.1223\n",
            "Epoch [243/250], Step [700/782], Loss: 0.0716\n",
            "Epoch [244/250], Step [0/782], Loss: 0.1834\n",
            "Epoch [244/250], Step [100/782], Loss: 0.0744\n",
            "Epoch [244/250], Step [200/782], Loss: 0.2092\n",
            "Epoch [244/250], Step [300/782], Loss: 0.0795\n",
            "Epoch [244/250], Step [400/782], Loss: 0.0614\n",
            "Epoch [244/250], Step [500/782], Loss: 0.0196\n",
            "Epoch [244/250], Step [600/782], Loss: 0.0335\n",
            "Epoch [244/250], Step [700/782], Loss: 0.0495\n",
            "Epoch [245/250], Step [0/782], Loss: 0.0638\n",
            "Epoch [245/250], Step [100/782], Loss: 0.0194\n",
            "Epoch [245/250], Step [200/782], Loss: 0.0211\n",
            "Epoch [245/250], Step [300/782], Loss: 0.0780\n",
            "Epoch [245/250], Step [400/782], Loss: 0.0506\n",
            "Epoch [245/250], Step [500/782], Loss: 0.0289\n",
            "Epoch [245/250], Step [600/782], Loss: 0.1866\n",
            "Epoch [245/250], Step [700/782], Loss: 0.0577\n",
            "Epoch [246/250], Step [0/782], Loss: 0.0528\n",
            "Epoch [246/250], Step [100/782], Loss: 0.0811\n",
            "Epoch [246/250], Step [200/782], Loss: 0.0226\n",
            "Epoch [246/250], Step [300/782], Loss: 0.0622\n",
            "Epoch [246/250], Step [400/782], Loss: 0.0993\n",
            "Epoch [246/250], Step [500/782], Loss: 0.0304\n",
            "Epoch [246/250], Step [600/782], Loss: 0.0413\n",
            "Epoch [246/250], Step [700/782], Loss: 0.0360\n",
            "Epoch [247/250], Step [0/782], Loss: 0.1036\n",
            "Epoch [247/250], Step [100/782], Loss: 0.0718\n",
            "Epoch [247/250], Step [200/782], Loss: 0.0536\n",
            "Epoch [247/250], Step [300/782], Loss: 0.1047\n",
            "Epoch [247/250], Step [400/782], Loss: 0.0364\n",
            "Epoch [247/250], Step [500/782], Loss: 0.1113\n",
            "Epoch [247/250], Step [600/782], Loss: 0.1662\n",
            "Epoch [247/250], Step [700/782], Loss: 0.0446\n",
            "Epoch [248/250], Step [0/782], Loss: 0.0801\n",
            "Epoch [248/250], Step [100/782], Loss: 0.0085\n",
            "Epoch [248/250], Step [200/782], Loss: 0.0813\n",
            "Epoch [248/250], Step [300/782], Loss: 0.0290\n",
            "Epoch [248/250], Step [400/782], Loss: 0.1311\n",
            "Epoch [248/250], Step [500/782], Loss: 0.0210\n",
            "Epoch [248/250], Step [600/782], Loss: 0.0232\n",
            "Epoch [248/250], Step [700/782], Loss: 0.0709\n",
            "Epoch [249/250], Step [0/782], Loss: 0.0127\n",
            "Epoch [249/250], Step [100/782], Loss: 0.0383\n",
            "Epoch [249/250], Step [200/782], Loss: 0.0195\n",
            "Epoch [249/250], Step [300/782], Loss: 0.0814\n",
            "Epoch [249/250], Step [400/782], Loss: 0.0620\n",
            "Epoch [249/250], Step [500/782], Loss: 0.0883\n",
            "Epoch [249/250], Step [600/782], Loss: 0.0964\n",
            "Epoch [249/250], Step [700/782], Loss: 0.0212\n",
            "Epoch [250/250], Step [0/782], Loss: 0.0090\n",
            "Epoch [250/250], Step [100/782], Loss: 0.0429\n",
            "Epoch [250/250], Step [200/782], Loss: 0.0677\n",
            "Epoch [250/250], Step [300/782], Loss: 0.0299\n",
            "Epoch [250/250], Step [400/782], Loss: 0.0117\n",
            "Epoch [250/250], Step [500/782], Loss: 0.0559\n",
            "Epoch [250/250], Step [600/782], Loss: 0.0410\n",
            "Epoch [250/250], Step [700/782], Loss: 0.0487\n",
            "Fine-tuning completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy after fine-tuning: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDnpVtglxAIL",
        "outputId": "61e6fbf9-88db-4dc5-9d5b-2ba8e56a7967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy after fine-tuning: 11.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(len(train_losses))  # Assuming `train_losses` is a list of loss values\n",
        "plt.plot(epochs, train_losses, label=\"Training Loss\")\n",
        "plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, train_accuracies, label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_accuracies, label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jjXqTgENxyFR",
        "outputId": "98d12739-35c6-4731-bb20-3b17224c5bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_losses' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-fb26000ee9a5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming `train_losses` is a list of loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Gouthami1907/moco.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAtEsmbI3NBG",
        "outputId": "3b13212e-8f2e-475f-a65d-cbe7cd287814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'moco' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ShivVIT2019/Machine_Learning_Project.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23nBW-7N3mYP",
        "outputId": "bfb798f4-2fd8-40ee-a4dd-12f05d18f401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Machine_Learning_Project'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add my_fork https://github.com/Gouthami1907/moco.git\n"
      ],
      "metadata": {
        "id": "fMmNvbg23-NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/moco/* /content/<group_repo>/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGnKG6BH4Eeo",
        "outputId": "bcc9b6f0-d8be-4d40-cec5-5aca7a3c0c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/Gouthami1907/moco\n",
            " * [new branch]      main       -> my_fork/main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git merge my_fork/main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhDdA4lX4HPH",
        "outputId": "31dd6ab2-a7a7-4c34-b7e9-73dd2fccd3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXAmCPFN4JWB",
        "outputId": "333f9b70-b782-472d-f7f7-6f1a9b296dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    }
  ]
}